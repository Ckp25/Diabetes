{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>GenHlth_X_PhysHlth</th>\n",
       "      <th>BMI_X_PhysActivity</th>\n",
       "      <th>Age_X_HighBP</th>\n",
       "      <th>Income_X_Education</th>\n",
       "      <th>Age_X_DiffWalk</th>\n",
       "      <th>health_bp_decay</th>\n",
       "      <th>low_ses</th>\n",
       "      <th>condition_count</th>\n",
       "      <th>health_cluster</th>\n",
       "      <th>risk_score_mult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.839397</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0    6     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0    3     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  GenHlth_X_PhysHlth  \\\n",
       "0                   0.0           0.0     0.0  ...                75.0   \n",
       "1                   0.0           1.0     0.0  ...                 0.0   \n",
       "\n",
       "   BMI_X_PhysActivity  Age_X_HighBP  Income_X_Education  Age_X_DiffWalk  \\\n",
       "0                 0.0           9.0                12.0             9.0   \n",
       "1                 3.0           0.0                 6.0             0.0   \n",
       "\n",
       "   health_bp_decay  low_ses  condition_count  health_cluster  risk_score_mult  \n",
       "0         1.839397        0              3.0               0           14.715  \n",
       "1         3.000000        0              0.0               1            3.210  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\PIMA\\data_2\\cleaned_3.csv')\n",
    "\n",
    "\n",
    "# Drop any unnecessary columns\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012\n",
       "0.0    213703\n",
       "2.0     35346\n",
       "1.0      4631\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diabetes_012'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.395690270352476, 1: 54.77570850202429, 2: 2.392332991477172}\n",
      "0:\ttest: 0.6759476\tbest: 0.6759476 (0)\ttotal: 142ms\tremaining: 2m 21s\n",
      "100:\ttest: 0.7348306\tbest: 0.7348306 (100)\ttotal: 11.8s\tremaining: 1m 45s\n",
      "200:\ttest: 0.7379563\tbest: 0.7380058 (193)\ttotal: 21.6s\tremaining: 1m 26s\n",
      "300:\ttest: 0.7377049\tbest: 0.7381395 (231)\ttotal: 31.4s\tremaining: 1m 12s\n",
      "400:\ttest: 0.7365872\tbest: 0.7381395 (231)\ttotal: 44.2s\tremaining: 1m 6s\n",
      "500:\ttest: 0.7352545\tbest: 0.7381395 (231)\ttotal: 1m 5s\tremaining: 1m 4s\n",
      "600:\ttest: 0.7345064\tbest: 0.7381395 (231)\ttotal: 1m 29s\tremaining: 59.1s\n",
      "700:\ttest: 0.7326145\tbest: 0.7381395 (231)\ttotal: 1m 47s\tremaining: 45.8s\n",
      "800:\ttest: 0.7309489\tbest: 0.7381395 (231)\ttotal: 1m 57s\tremaining: 29.2s\n",
      "900:\ttest: 0.7297242\tbest: 0.7381395 (231)\ttotal: 2m 7s\tremaining: 14s\n",
      "999:\ttest: 0.7284599\tbest: 0.7381395 (231)\ttotal: 2m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7381395005\n",
      "bestIteration = 231\n",
      "\n",
      "Shrink model to first 232 iterations.\n",
      "\n",
      "Standard Prediction Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.34      0.50     42741\n",
      "         1.0       0.02      0.91      0.05       926\n",
      "         2.0       0.58      0.05      0.09      7069\n",
      "\n",
      "    accuracy                           0.31     50736\n",
      "   macro avg       0.53      0.43      0.21     50736\n",
      "weighted avg       0.91      0.31      0.44     50736\n",
      "\n",
      "\n",
      "Refined Threshold Metrics (prioritizing class 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.06      0.11     42741\n",
      "         1.0       0.02      0.99      0.04       926\n",
      "         2.0       0.00      0.00      0.00      7069\n",
      "\n",
      "    accuracy                           0.07     50736\n",
      "   macro avg       0.34      0.35      0.05     50736\n",
      "weighted avg       0.84      0.07      0.09     50736\n",
      "\n",
      "\n",
      "Direct Threshold Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.39      0.56     42741\n",
      "         1.0       0.03      0.91      0.05       926\n",
      "         2.0       0.00      0.00      0.00      7069\n",
      "\n",
      "    accuracy                           0.35     50736\n",
      "   macro avg       0.34      0.44      0.20     50736\n",
      "weighted avg       0.83      0.35      0.47     50736\n",
      "\n",
      "\n",
      "Standard prediction recalls:\n",
      "Class 0 Recall: 0.3381\n",
      "Class 1 Recall: 0.9060\n",
      "Class 2 Recall: 0.0471\n",
      "\n",
      "Refined prediction recalls:\n",
      "Class 0 Recall: 0.0569\n",
      "Class 1 Recall: 0.9935\n",
      "Class 2 Recall: 0.0000\n",
      "\n",
      "Direct prediction recalls:\n",
      "Class 0 Recall: 0.3930\n",
      "Class 1 Recall: 0.9136\n",
      "Class 2 Recall: 0.0000\n",
      "\n",
      "Exploring different threshold combinations:\n",
      "Thresholds [0.4, 0.1, 0.3]: Class recalls: [0.393, 0.9136, 0.0]\n",
      "Thresholds [0.4, 0.2, 0.3]: Class recalls: [0.393, 0.9136, 0.0001]\n",
      "Thresholds [0.35, 0.15, 0.35]: Class recalls: [0.4498, 0.8888, 0.0]\n",
      "Thresholds [0.4, 0.2, 0.25]: Class recalls: [0.393, 0.9136, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Let's assume X and y are your features and target variable\n",
    "# X = your_dataframe\n",
    "# y = your_target_variable (with values 0, 1, 2)\n",
    "\n",
    "# For demonstration, I'll generate some sample data\n",
    "# In practice, you would use your actual data\n",
    "y = df['Diabetes_012']\n",
    "X = df.drop('Diabetes_012',axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "def calculate_class_weights(y):\n",
    "    unique_classes = np.unique(y)\n",
    "    class_counts = np.bincount(y.astype(int))\n",
    "    total_samples = len(y)\n",
    "    \n",
    "    n_classes = len(unique_classes)\n",
    "    weights = {}\n",
    "    for i, cls in enumerate(unique_classes):\n",
    "        weights[int(cls)] = total_samples / (n_classes * class_counts[int(cls)])\n",
    "    return weights\n",
    "\n",
    "# Get class weights\n",
    "class_weights_dict = calculate_class_weights(y_train)\n",
    "\n",
    "# Adjust weights based on your results\n",
    "# Since class 2 already has good recall but class 1 is poor, increase weight for class 1\n",
    "if 1 in class_weights_dict and 2 in class_weights_dict:\n",
    "    class_weights_dict[1] = class_weights_dict[1] * 3  # Triple the weight for class 1\n",
    "    # Don't modify class 2 weight since it's already performing well\n",
    "\n",
    "print(f\"Class weights: {class_weights_dict}\")\n",
    "\n",
    "# Initialize CatBoost classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=class_weights_dict,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    eval_metric='AUC:type=Mu'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "# Get prediction probabilities\n",
    "pred_probs = model.predict_proba(X_test)\n",
    "\n",
    "# Improved thresholding function based on our findings\n",
    "def refined_class_thresholds(probs):\n",
    "    \"\"\"\n",
    "    Based on the results, we need to:\n",
    "    1. Maintain good class 2 recall (was 90% without custom thresholds)\n",
    "    2. Improve class 1 recall (was only 3.5%)\n",
    "    3. Keep reasonable class 0 performance\n",
    "    \"\"\"\n",
    "    # Let's try class-specific thresholds tuned to your dataset\n",
    "    thresholds = [0.35, 0.15, 0.30]  # for classes 0, 1, 2\n",
    "    \n",
    "    # Initialize predictions array\n",
    "    predictions = np.zeros(len(probs))\n",
    "    \n",
    "    # First priority: Identify class 1 (very poor recall in standard model)\n",
    "    for i, prob_row in enumerate(probs):\n",
    "        if prob_row[1] > thresholds[1]:\n",
    "            predictions[i] = 1\n",
    "        elif prob_row[2] > thresholds[2]:\n",
    "            predictions[i] = 2\n",
    "        elif prob_row[0] > thresholds[0]:\n",
    "            predictions[i] = 0\n",
    "        else:\n",
    "            # For any remaining cases, use argmax\n",
    "            predictions[i] = np.argmax(prob_row)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Apply standard prediction\n",
    "y_pred_standard = model.predict(X_test)\n",
    "\n",
    "# Apply our refined thresholds\n",
    "y_pred_refined = refined_class_thresholds(pred_probs)\n",
    "\n",
    "# Also try a version focused purely on thresholds without changing order\n",
    "def direct_class_thresholds(probs, thresholds=[0.4, 0.15, 0.3]):\n",
    "    \"\"\"Simple thresholding without prioritizing any class\"\"\"\n",
    "    predictions = np.zeros(len(probs))\n",
    "    \n",
    "    for i, prob_row in enumerate(probs):\n",
    "        # Check each class against its threshold\n",
    "        for class_idx, threshold in enumerate(thresholds):\n",
    "            if prob_row[class_idx] > threshold:\n",
    "                # If probability exceeds class-specific threshold, assign this class\n",
    "                predictions[i] = class_idx\n",
    "                break\n",
    "        \n",
    "        # If no threshold was met, use argmax\n",
    "        if predictions[i] == 0 and prob_row[0] <= thresholds[0]:\n",
    "            predictions[i] = np.argmax(prob_row)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Apply direct thresholds\n",
    "y_pred_direct = direct_class_thresholds(pred_probs)\n",
    "\n",
    "# Evaluate results\n",
    "print(\"\\nStandard Prediction Metrics:\")\n",
    "print(classification_report(y_test, y_pred_standard))\n",
    "\n",
    "print(\"\\nRefined Threshold Metrics (prioritizing class 1):\")\n",
    "print(classification_report(y_test, y_pred_refined))\n",
    "\n",
    "print(\"\\nDirect Threshold Metrics:\")\n",
    "print(classification_report(y_test, y_pred_direct))\n",
    "\n",
    "# Calculate class-specific recalls\n",
    "for strategy, y_pred in [(\"Standard\", y_pred_standard), \n",
    "                         (\"Refined\", y_pred_refined), \n",
    "                         (\"Direct\", y_pred_direct)]:\n",
    "    print(f\"\\n{strategy} prediction recalls:\")\n",
    "    for i in range(3):  # For classes 0, 1, 2\n",
    "        if i in np.unique(y_test):  # Only calculate for classes that exist in test set\n",
    "            recall = recall_score(y_test == i, y_pred == i)\n",
    "            print(f\"Class {i} Recall: {recall:.4f}\")\n",
    "\n",
    "# Try different threshold combinations to find optimal settings\n",
    "print(\"\\nExploring different threshold combinations:\")\n",
    "threshold_options = [\n",
    "    [0.4, 0.1, 0.3],   # Lower threshold for class 1\n",
    "    [0.4, 0.2, 0.3],   # Slightly higher threshold for class 1\n",
    "    [0.35, 0.15, 0.35], # Higher threshold for class 2\n",
    "    [0.4, 0.2, 0.25]    # Lower threshold for class 2\n",
    "]\n",
    "\n",
    "for thresholds in threshold_options:\n",
    "    y_pred = direct_class_thresholds(pred_probs, thresholds)\n",
    "    recalls = []\n",
    "    for i in range(3):\n",
    "        if i in np.unique(y_test):\n",
    "            recall = recall_score(y_test == i, y_pred == i)\n",
    "            recalls.append(recall)\n",
    "    \n",
    "    print(f\"Thresholds {thresholds}: Class recalls: {[round(r, 4) for r in recalls]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes - X: (202944, 33), y: (202944,)\n",
      "Class distribution in training set: [170962   3705  28277]\n",
      "Binary class distribution in training set: [170962  31982]\n",
      "Binary model class weights: {0: 1.0, 1: 5.345569382777812}\n",
      "0:\tlearn: 0.6762877\ttest: 0.6766480\tbest: 0.6766480 (0)\ttotal: 133ms\tremaining: 2m 13s\n",
      "100:\tlearn: 0.5095463\ttest: 0.5151712\tbest: 0.5151712 (100)\ttotal: 6.07s\tremaining: 54.1s\n",
      "200:\tlearn: 0.5051043\ttest: 0.5129590\tbest: 0.5129401 (198)\ttotal: 11.5s\tremaining: 45.7s\n",
      "300:\tlearn: 0.5014517\ttest: 0.5122024\tbest: 0.5122024 (300)\ttotal: 15.9s\tremaining: 37s\n",
      "400:\tlearn: 0.4979810\ttest: 0.5119325\tbest: 0.5119278 (392)\ttotal: 19.9s\tremaining: 29.8s\n",
      "500:\tlearn: 0.4949839\ttest: 0.5119471\tbest: 0.5119278 (392)\ttotal: 23.8s\tremaining: 23.7s\n",
      "600:\tlearn: 0.4922731\ttest: 0.5123480\tbest: 0.5119278 (392)\ttotal: 27.8s\tremaining: 18.4s\n",
      "700:\tlearn: 0.4897417\ttest: 0.5127385\tbest: 0.5119278 (392)\ttotal: 31.7s\tremaining: 13.5s\n",
      "800:\tlearn: 0.4873490\ttest: 0.5130814\tbest: 0.5119278 (392)\ttotal: 35.8s\tremaining: 8.89s\n",
      "900:\tlearn: 0.4850348\ttest: 0.5133790\tbest: 0.5119278 (392)\ttotal: 40.3s\tremaining: 4.43s\n",
      "999:\tlearn: 0.4828476\ttest: 0.5139197\tbest: 0.5119278 (392)\ttotal: 44.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5119278033\n",
      "bestIteration = 392\n",
      "\n",
      "Shrink model to first 393 iterations.\n",
      "\n",
      "----- Stage 1 Binary Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.51      0.67     42741\n",
      "           1       0.26      0.92      0.41      7995\n",
      "\n",
      "    accuracy                           0.58     50736\n",
      "   macro avg       0.62      0.72      0.54     50736\n",
      "weighted avg       0.86      0.58      0.63     50736\n",
      "\n",
      "Recall for positive cases (1 or 2): 0.9193\n",
      "\n",
      "Positive cases for stage 2 training: 31982\n",
      "Class distribution in positive cases: [ 3705 28277]\n",
      "Positive cases model class weights: {0: 1.0, 1: 0.13102521483891502}\n",
      "0:\tlearn: 0.6905502\ttotal: 11.7ms\tremaining: 11.7s\n",
      "100:\tlearn: 0.6359295\ttotal: 1.1s\tremaining: 9.84s\n",
      "200:\tlearn: 0.6108109\ttotal: 2.17s\tremaining: 8.64s\n",
      "300:\tlearn: 0.5891080\ttotal: 3.22s\tremaining: 7.47s\n",
      "400:\tlearn: 0.5690322\ttotal: 4.57s\tremaining: 6.82s\n",
      "500:\tlearn: 0.5511562\ttotal: 5.91s\tremaining: 5.88s\n",
      "600:\tlearn: 0.5346778\ttotal: 7.25s\tremaining: 4.82s\n",
      "700:\tlearn: 0.5192319\ttotal: 8.59s\tremaining: 3.66s\n",
      "800:\tlearn: 0.5053456\ttotal: 9.91s\tremaining: 2.46s\n",
      "900:\tlearn: 0.4920912\ttotal: 11.2s\tremaining: 1.23s\n",
      "999:\tlearn: 0.4796514\ttotal: 12.3s\tremaining: 0us\n",
      "\n",
      "----- Stage 2 Positive Cases Model Evaluation (on actual positives) -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.08       926\n",
      "           1       0.89      0.99      0.93      7069\n",
      "\n",
      "    accuracy                           0.88      7995\n",
      "   macro avg       0.61      0.52      0.51      7995\n",
      "weighted avg       0.82      0.88      0.84      7995\n",
      "\n",
      "Recall for class 1: 0.0475\n",
      "Recall for class 2: 0.9874\n",
      "\n",
      "----- Combined Hierarchical Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.51      0.67     42741\n",
      "           1       0.02      0.01      0.01       926\n",
      "           2       0.24      0.92      0.37      7069\n",
      "\n",
      "    accuracy                           0.56     50736\n",
      "   macro avg       0.41      0.48      0.35     50736\n",
      "weighted avg       0.85      0.56      0.62     50736\n",
      "\n",
      "\n",
      "Class-specific Recall for Hierarchical Model:\n",
      "Class 0 Recall: 0.5143\n",
      "Class 1 Recall: 0.0054\n",
      "Class 2 Recall: 0.9240\n",
      "Error subsetting X: iLocation based boolean indexing on an integer type is not available\n",
      "X type: <class 'pandas.core.frame.DataFrame'>\n",
      "Positive mask shape: (50736,)\n",
      "\n",
      "----- Threshold Tuning Results -----\n",
      "Top 5 settings for class 2 recall:\n",
      "Binary threshold: 0.2, Positive threshold: 0.15\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0011\n",
      "  Class 2 recall: 0.9653\n",
      "\n",
      "Binary threshold: 0.2, Positive threshold: 0.2\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0043\n",
      "  Class 2 recall: 0.9641\n",
      "\n",
      "Binary threshold: 0.2, Positive threshold: 0.25\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0162\n",
      "  Class 2 recall: 0.9578\n",
      "\n",
      "Binary threshold: 0.25, Positive threshold: 0.15\n",
      "  Class 0 recall: 0.4607\n",
      "  Class 1 recall: 0.0000\n",
      "  Class 2 recall: 0.9506\n",
      "\n",
      "Binary threshold: 0.25, Positive threshold: 0.2\n",
      "  Class 0 recall: 0.4607\n",
      "  Class 1 recall: 0.0032\n",
      "  Class 2 recall: 0.9495\n",
      "\n",
      "Top 5 settings for balanced recall (prioritizing classes 1 and 2):\n",
      "Binary threshold: 0.2, Positive threshold: 0.35\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0734\n",
      "  Class 2 recall: 0.9199\n",
      "\n",
      "Binary threshold: 0.2, Positive threshold: 0.3\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0378\n",
      "  Class 2 recall: 0.9450\n",
      "\n",
      "Binary threshold: 0.25, Positive threshold: 0.35\n",
      "  Class 0 recall: 0.4607\n",
      "  Class 1 recall: 0.0616\n",
      "  Class 2 recall: 0.9102\n",
      "\n",
      "Binary threshold: 0.2, Positive threshold: 0.25\n",
      "  Class 0 recall: 0.4016\n",
      "  Class 1 recall: 0.0162\n",
      "  Class 2 recall: 0.9578\n",
      "\n",
      "Binary threshold: 0.25, Positive threshold: 0.3\n",
      "  Class 0 recall: 0.4607\n",
      "  Class 1 recall: 0.0292\n",
      "  Class 2 recall: 0.9335\n",
      "\n",
      "\n",
      "Example usage of prediction function:\n",
      "predictions = predict_diabetes_severity(new_data)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create binary target for first stage model (0 vs [1,2])\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X, y, y_binary, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training data shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"Binary class distribution in training set: {np.bincount(y_binary_train)}\")\n",
    "\n",
    "# ----- STAGE 1: Binary Classification Model (0 vs [1,2]) -----\n",
    "\n",
    "# Calculate class weights for binary model\n",
    "def calculate_binary_weights(y):\n",
    "    counts = np.bincount(y)\n",
    "    return {0: 1.0, 1: counts[0] / counts[1]}\n",
    "\n",
    "binary_weights = calculate_binary_weights(y_binary_train)\n",
    "print(f\"Binary model class weights: {binary_weights}\")\n",
    "\n",
    "# Initialize first stage model (binary classifier)\n",
    "binary_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',  # Binary classification\n",
    "    class_weights=binary_weights,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train binary model\n",
    "binary_model.fit(X_train, y_binary_train, eval_set=(X_test, y_binary_test))\n",
    "\n",
    "# Get predictions from binary model\n",
    "binary_probs = binary_model.predict_proba(X_test)[:, 1]  # Probability of being class 1 or 2\n",
    "\n",
    "# Apply threshold to binary model (lower threshold to favor recall)\n",
    "binary_threshold = 0.3  # This can be tuned\n",
    "binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "\n",
    "# Evaluate binary model\n",
    "print(\"\\n----- Stage 1 Binary Model Evaluation -----\")\n",
    "print(classification_report(y_binary_test, binary_preds))\n",
    "print(f\"Recall for positive cases (1 or 2): {recall_score(y_binary_test, binary_preds):.4f}\")\n",
    "\n",
    "# ----- STAGE 2: Multiclass Model (1 vs 2) for positive cases only -----\n",
    "\n",
    "# Filter training data to include only classes 1 and 2\n",
    "mask_train = y_train > 0\n",
    "X_train_positives = X_train[mask_train]\n",
    "y_train_positives = y_train[mask_train]\n",
    "\n",
    "# Adjust class values from [1,2] to [0,1] for the second model\n",
    "y_train_positives = y_train_positives - 1\n",
    "\n",
    "print(f\"\\nPositive cases for stage 2 training: {len(X_train_positives)}\")\n",
    "print(f\"Class distribution in positive cases: {np.bincount(y_train_positives.astype(int))}\")\n",
    "\n",
    "# Calculate class weights for the second model\n",
    "def calculate_positive_weights(y):\n",
    "    counts = np.bincount(y)\n",
    "    if len(counts) < 2:\n",
    "        return {0: 1.0}  # Handle edge case\n",
    "    return {0: 1.0, 1: counts[0] / counts[1]}\n",
    "\n",
    "positive_weights = calculate_positive_weights(y_train_positives)\n",
    "print(f\"Positive cases model class weights: {positive_weights}\")\n",
    "\n",
    "# Initialize second stage model (classifier for positive cases)\n",
    "positive_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',  # Binary between 1 and 2\n",
    "    class_weights=positive_weights,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train positive cases model if we have enough samples\n",
    "if len(np.unique(y_train_positives)) > 1 and len(y_train_positives) > 10:\n",
    "    positive_model.fit(X_train_positives, y_train_positives)\n",
    "    \n",
    "    # Extract actual positive cases from test set for evaluation\n",
    "    mask_test_actual_positives = y_test > 0\n",
    "    X_test_actual_positives = X_test[mask_test_actual_positives]\n",
    "    y_test_actual_positives = y_test[mask_test_actual_positives] - 1\n",
    "    \n",
    "    if len(X_test_actual_positives) > 0:\n",
    "        # Get predictions on actual positive cases\n",
    "        positive_probs = positive_model.predict_proba(X_test_actual_positives)[:, 1]\n",
    "        \n",
    "        # Apply threshold (lower threshold to favor class 2 recall)\n",
    "        positive_threshold = 0.25  # This can be tuned\n",
    "        positive_preds = (positive_probs >= positive_threshold).astype(int)\n",
    "        \n",
    "        # Evaluate positive model on actual positive cases\n",
    "        print(\"\\n----- Stage 2 Positive Cases Model Evaluation (on actual positives) -----\")\n",
    "        print(classification_report(y_test_actual_positives, positive_preds))\n",
    "        \n",
    "        # Class-specific recalls for the second model\n",
    "        for cls in range(2):  # 0 means class 1, 1 means class 2\n",
    "            recall = recall_score(y_test_actual_positives == cls, positive_preds == cls)\n",
    "            print(f\"Recall for class {cls+1}: {recall:.4f}\")\n",
    "else:\n",
    "    print(\"\\nWARNING: Not enough positive samples to train second stage model\")\n",
    "\n",
    "# ----- COMBINE MODELS FOR FINAL PREDICTION -----\n",
    "\n",
    "# Function to make predictions using both models\n",
    "def hierarchical_predict(X, binary_model, positive_model, binary_threshold=0.3, positive_threshold=0.25):\n",
    "    # Stage 1: Predict if positive (class 1 or 2) or negative (class 0)\n",
    "    binary_probs = binary_model.predict_proba(X)[:, 1]\n",
    "    binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "    \n",
    "    # Initialize with all zeros\n",
    "    final_preds = np.zeros(len(X))\n",
    "    \n",
    "            # Find samples predicted as positive (1 or 2)\n",
    "    positive_indices = np.where(binary_preds == 1)[0]\n",
    "    \n",
    "    if len(positive_indices) > 0:\n",
    "        # Stage 2: For positive predictions, determine if class 1 or 2\n",
    "        try:\n",
    "            if hasattr(X, 'iloc'):\n",
    "                X_positives = X.iloc[positive_indices]\n",
    "            else:\n",
    "                X_positives = X[positive_indices]\n",
    "        except Exception as e:\n",
    "            print(f\"Error subsetting X positives: {e}\")\n",
    "            # Fallback approach\n",
    "            if hasattr(X, 'loc'):\n",
    "                X_positives = X.loc[positive_indices]\n",
    "            else:\n",
    "                X_positives = X[positive_indices, :]\n",
    "        positive_probs = positive_model.predict_proba(X_positives)[:, 1]\n",
    "        positive_preds = (positive_probs >= positive_threshold).astype(int)\n",
    "        \n",
    "        # Convert from [0,1] back to [1,2]\n",
    "        positive_preds = positive_preds + 1\n",
    "        \n",
    "        # Assign to final predictions\n",
    "        final_preds[positive_indices] = positive_preds\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# Make hierarchical predictions\n",
    "y_pred_hierarchical = hierarchical_predict(\n",
    "    X_test, binary_model, positive_model, \n",
    "    binary_threshold=binary_threshold, \n",
    "    positive_threshold=positive_threshold\n",
    ")\n",
    "\n",
    "# Evaluate final hierarchical model\n",
    "print(\"\\n----- Combined Hierarchical Model Evaluation -----\")\n",
    "print(classification_report(y_test, y_pred_hierarchical))\n",
    "\n",
    "# Class-specific recall comparison\n",
    "print(\"\\nClass-specific Recall for Hierarchical Model:\")\n",
    "for cls in range(3):\n",
    "    if cls in np.unique(y_test):\n",
    "        recall = recall_score(y_test == cls, y_pred_hierarchical == cls)\n",
    "        print(f\"Class {cls} Recall: {recall:.4f}\")\n",
    "\n",
    "# ----- THRESHOLD TUNING -----\n",
    "\n",
    "# Function to tune thresholds for both stages\n",
    "def tune_hierarchical_thresholds(X, y, binary_model, positive_model):\n",
    "    binary_probs = binary_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Mask for actual positive cases\n",
    "    positive_mask = y > 0\n",
    "    \n",
    "    # Handle X depending on type (DataFrame or numpy array)\n",
    "    try:\n",
    "        if hasattr(X, 'iloc'):\n",
    "            X_positive = X.iloc[positive_mask]\n",
    "        else:\n",
    "            X_positive = X[positive_mask]\n",
    "    except Exception as e:\n",
    "        print(f\"Error subsetting X: {e}\")\n",
    "        print(f\"X type: {type(X)}\")\n",
    "        print(f\"Positive mask shape: {positive_mask.shape}\")\n",
    "        # Fallback approach\n",
    "        if hasattr(X, 'loc'):\n",
    "            X_positive = X.loc[positive_mask]\n",
    "        else:\n",
    "            indices = np.where(positive_mask)[0]\n",
    "            X_positive = X[indices]\n",
    "    \n",
    "    y_positive = y[positive_mask] - 1  # Adjust to [0,1]\n",
    "    \n",
    "    if len(X_positive) > 0:\n",
    "        positive_probs = positive_model.predict_proba(X_positive)[:, 1]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test different threshold combinations\n",
    "    binary_thresholds = [0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "    positive_thresholds = [0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "    \n",
    "    for b_thresh in binary_thresholds:\n",
    "        for p_thresh in positive_thresholds:\n",
    "            # Make predictions\n",
    "            preds = hierarchical_predict(\n",
    "                X, binary_model, positive_model,\n",
    "                binary_threshold=b_thresh,\n",
    "                positive_threshold=p_thresh\n",
    "            )\n",
    "            \n",
    "            # Calculate class-specific recalls\n",
    "            recalls = []\n",
    "            for cls in range(3):\n",
    "                if cls in np.unique(y):\n",
    "                    recall = recall_score(y == cls, preds == cls)\n",
    "                    recalls.append(recall)\n",
    "                else:\n",
    "                    recalls.append(np.nan)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'binary_threshold': b_thresh,\n",
    "                'positive_threshold': p_thresh,\n",
    "                'class0_recall': recalls[0],\n",
    "                'class1_recall': recalls[1] if len(recalls) > 1 else np.nan,\n",
    "                'class2_recall': recalls[2] if len(recalls) > 2 else np.nan,\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Tune thresholds\n",
    "threshold_results = tune_hierarchical_thresholds(X_test, y_test, binary_model, positive_model)\n",
    "\n",
    "# Sort results by different criteria\n",
    "print(\"\\n----- Threshold Tuning Results -----\")\n",
    "print(\"Top 5 settings for class 2 recall:\")\n",
    "top_class2 = sorted(threshold_results, key=lambda x: x['class2_recall'], reverse=True)[:5]\n",
    "for result in top_class2:\n",
    "    print(f\"Binary threshold: {result['binary_threshold']}, Positive threshold: {result['positive_threshold']}\")\n",
    "    print(f\"  Class 0 recall: {result['class0_recall']:.4f}\")\n",
    "    print(f\"  Class 1 recall: {result['class1_recall']:.4f}\")\n",
    "    print(f\"  Class 2 recall: {result['class2_recall']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Top 5 settings for balanced recall (prioritizing classes 1 and 2):\")\n",
    "def balance_score(result):\n",
    "    # Weighted average with emphasis on classes 1 and 2\n",
    "    return result['class1_recall'] * 0.4 + result['class2_recall'] * 0.5 + result['class0_recall'] * 0.1\n",
    "\n",
    "top_balanced = sorted(threshold_results, key=balance_score, reverse=True)[:5]\n",
    "for result in top_balanced:\n",
    "    print(f\"Binary threshold: {result['binary_threshold']}, Positive threshold: {result['positive_threshold']}\")\n",
    "    print(f\"  Class 0 recall: {result['class0_recall']:.4f}\")\n",
    "    print(f\"  Class 1 recall: {result['class1_recall']:.4f}\")\n",
    "    print(f\"  Class 2 recall: {result['class2_recall']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Save models\n",
    "binary_model.save_model('catboost_binary_diabetes.cbm')\n",
    "positive_model.save_model('catboost_positive_diabetes.cbm')\n",
    "\n",
    "# Create a function to apply the hierarchical model to new data\n",
    "def predict_diabetes_severity(X_new, binary_model_path='catboost_binary_diabetes.cbm', \n",
    "                             positive_model_path='catboost_positive_diabetes.cbm',\n",
    "                             binary_threshold=0.3, positive_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Predict diabetes severity for new data using the hierarchical model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : DataFrame or array\n",
    "        New features to predict on\n",
    "    binary_model_path : str\n",
    "        Path to saved binary model\n",
    "    positive_model_path : str\n",
    "        Path to saved positive cases model\n",
    "    binary_threshold : float\n",
    "        Threshold for binary model\n",
    "    positive_threshold : float\n",
    "        Threshold for positive cases model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0 = no diabetes, 1 = moderate diabetes, 2 = severe diabetes\n",
    "    \"\"\"\n",
    "    # Load models\n",
    "    binary_model = CatBoostClassifier()\n",
    "    binary_model.load_model(binary_model_path)\n",
    "    \n",
    "    positive_model = CatBoostClassifier()\n",
    "    positive_model.load_model(positive_model_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    return hierarchical_predict(X_new, binary_model, positive_model, \n",
    "                               binary_threshold, positive_threshold)\n",
    "\n",
    "print(\"\\nExample usage of prediction function:\")\n",
    "print(\"predictions = predict_diabetes_severity(new_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: [170962   3705  28277]\n",
      "Binary class distribution in training set: [170962  31982]\n",
      "Binary model class weights: {0: 1.0, 1: 5.0}\n",
      "0:\tlearn: 0.6757686\ttest: 0.6759770\tbest: 0.6759770 (0)\ttotal: 46ms\tremaining: 46s\n",
      "100:\tlearn: 0.5097676\ttest: 0.5155124\tbest: 0.5155124 (100)\ttotal: 6.3s\tremaining: 56.1s\n",
      "200:\tlearn: 0.5052307\ttest: 0.5133545\tbest: 0.5133545 (200)\ttotal: 11.4s\tremaining: 45.2s\n",
      "300:\tlearn: 0.5013412\ttest: 0.5124749\tbest: 0.5124749 (300)\ttotal: 16.1s\tremaining: 37.5s\n",
      "400:\tlearn: 0.4977935\ttest: 0.5122168\tbest: 0.5121960 (399)\ttotal: 21s\tremaining: 31.4s\n",
      "500:\tlearn: 0.4945215\ttest: 0.5122243\tbest: 0.5120909 (463)\ttotal: 25.5s\tremaining: 25.4s\n",
      "600:\tlearn: 0.4915330\ttest: 0.5123922\tbest: 0.5120909 (463)\ttotal: 30.6s\tremaining: 20.3s\n",
      "700:\tlearn: 0.4888457\ttest: 0.5125133\tbest: 0.5120909 (463)\ttotal: 35.4s\tremaining: 15.1s\n",
      "800:\tlearn: 0.4861168\ttest: 0.5127654\tbest: 0.5120909 (463)\ttotal: 41.6s\tremaining: 10.3s\n",
      "900:\tlearn: 0.4834734\ttest: 0.5131256\tbest: 0.5120909 (463)\ttotal: 48.3s\tremaining: 5.3s\n",
      "999:\tlearn: 0.4809805\ttest: 0.5136039\tbest: 0.5120909 (463)\ttotal: 54s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5120909141\n",
      "bestIteration = 463\n",
      "\n",
      "Shrink model to first 464 iterations.\n",
      "\n",
      "----- Stage 1 Binary Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.41      0.58     42741\n",
      "           1       0.23      0.96      0.38      7995\n",
      "\n",
      "    accuracy                           0.50     50736\n",
      "   macro avg       0.61      0.68      0.48     50736\n",
      "weighted avg       0.86      0.50      0.55     50736\n",
      "\n",
      "Recall for positive cases (1 or 2): 0.9553\n",
      "\n",
      "Class distribution in positive cases: [ 3705 28277]\n",
      "Applying SMOTE to balance positive classes...\n",
      "After SMOTE - Class distribution: [28277 28277]\n",
      "Positive cases model class weights: {0: 8.0, 1: 1.0}\n",
      "0:\tlearn: 0.6650088\ttotal: 33.9ms\tremaining: 33.9s\n",
      "100:\tlearn: 0.1656191\ttotal: 3.44s\tremaining: 30.6s\n",
      "200:\tlearn: 0.1579658\ttotal: 6.37s\tremaining: 25.3s\n",
      "300:\tlearn: 0.1538527\ttotal: 9.92s\tremaining: 23s\n",
      "400:\tlearn: 0.1493802\ttotal: 12.5s\tremaining: 18.7s\n",
      "500:\tlearn: 0.1450544\ttotal: 14.9s\tremaining: 14.8s\n",
      "600:\tlearn: 0.1415448\ttotal: 17.2s\tremaining: 11.4s\n",
      "700:\tlearn: 0.1381632\ttotal: 19.8s\tremaining: 8.44s\n",
      "800:\tlearn: 0.1352160\ttotal: 22.1s\tremaining: 5.48s\n",
      "900:\tlearn: 0.1324207\ttotal: 24.6s\tremaining: 2.71s\n",
      "999:\tlearn: 0.1298008\ttotal: 27.4s\tremaining: 0us\n",
      "\n",
      "----- Testing thresholds for Stage 2 model -----\n",
      "Threshold 0.05: Class 1 recall: 0.9978, Class 2 recall: 0.0038, Combined: 0.6996\n",
      "Threshold 0.10: Class 1 recall: 0.9849, Class 2 recall: 0.0184, Combined: 0.6949\n",
      "Threshold 0.15: Class 1 recall: 0.9762, Class 2 recall: 0.0424, Combined: 0.6961\n",
      "Threshold 0.20: Class 1 recall: 0.9611, Class 2 recall: 0.0796, Combined: 0.6967\n",
      "Threshold 0.25: Class 1 recall: 0.9352, Class 2 recall: 0.1327, Combined: 0.6945\n",
      "Threshold 0.30: Class 1 recall: 0.8996, Class 2 recall: 0.1891, Combined: 0.6864\n",
      "Threshold 0.35: Class 1 recall: 0.8402, Class 2 recall: 0.2693, Combined: 0.6689\n",
      "Threshold 0.40: Class 1 recall: 0.7646, Class 2 recall: 0.3706, Combined: 0.6464\n",
      "Threshold 0.45: Class 1 recall: 0.6587, Class 2 recall: 0.4858, Combined: 0.6069\n",
      "Threshold 0.50: Class 1 recall: 0.5616, Class 2 recall: 0.6125, Combined: 0.5768\n",
      "\n",
      "Best threshold: 0.05 with recalls - Class 1: 0.9978, Class 2: 0.0038\n",
      "\n",
      "----- Combined Hierarchical Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.41      0.58     42741\n",
      "           1       0.03      0.89      0.05       926\n",
      "           2       0.60      0.00      0.01      7069\n",
      "\n",
      "    accuracy                           0.37     50736\n",
      "   macro avg       0.54      0.44      0.21     50736\n",
      "weighted avg       0.91      0.37      0.49     50736\n",
      "\n",
      "\n",
      "Class-specific Recall for Hierarchical Model:\n",
      "Class 0 Recall: 0.4141\n",
      "Class 1 Recall: 0.8888\n",
      "Class 2 Recall: 0.0038\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r'D:\\PIMA\\data_2\\cleaned_3.csv')  # Adjust path as needed\n",
    "\n",
    "# Set up features and target\n",
    "X = data.drop('Diabetes_012', axis=1)  # Adjust column name as needed\n",
    "y = data['Diabetes_012'].astype(int)  # Ensure this has 0, 1, 2 values\n",
    "\n",
    "# Create binary target for first stage model (0 vs [1,2])\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X, y, y_binary, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"Binary class distribution in training set: {np.bincount(y_binary_train)}\")\n",
    "\n",
    "# ----- STAGE 1: Binary Classification Model (0 vs [1,2]) -----\n",
    "\n",
    "# Calculate class weights for binary model\n",
    "binary_weights = {0: 1.0, 1: 5.0}  # Substantial weight to positives\n",
    "print(f\"Binary model class weights: {binary_weights}\")\n",
    "\n",
    "# Initialize first stage model (binary classifier)\n",
    "binary_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    class_weights=binary_weights,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train binary model\n",
    "binary_model.fit(X_train, y_binary_train, eval_set=(X_test, y_binary_test))\n",
    "\n",
    "# Get predictions from binary model\n",
    "binary_probs = binary_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply threshold to binary model (lower threshold to favor recall)\n",
    "binary_threshold = 0.2  # Even lower threshold to catch more positive cases\n",
    "binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "\n",
    "# Evaluate binary model\n",
    "print(\"\\n----- Stage 1 Binary Model Evaluation -----\")\n",
    "print(classification_report(y_binary_test, binary_preds))\n",
    "print(f\"Recall for positive cases (1 or 2): {recall_score(y_binary_test, binary_preds):.4f}\")\n",
    "\n",
    "# ----- STAGE 2: Multiclass Model (1 vs 2) for positive cases only -----\n",
    "\n",
    "# Filter training data to include only classes 1 and 2\n",
    "mask_train = y_train > 0\n",
    "X_train_positives = X_train[mask_train]\n",
    "y_train_positives = y_train[mask_train]\n",
    "\n",
    "# Adjust class values from [1,2] to [0,1] for the second model\n",
    "y_train_positives = y_train_positives - 1\n",
    "\n",
    "print(f\"\\nClass distribution in positive cases: {np.bincount(y_train_positives.astype(int))}\")\n",
    "\n",
    "# Apply SMOTE to balance classes 1 and 2\n",
    "try:\n",
    "    print(\"Applying SMOTE to balance positive classes...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_pos_resampled, y_train_pos_resampled = smote.fit_resample(X_train_positives, y_train_positives)\n",
    "    print(f\"After SMOTE - Class distribution: {np.bincount(y_train_pos_resampled.astype(int))}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error applying SMOTE: {e}\")\n",
    "    print(\"Falling back to class weights...\")\n",
    "    X_train_pos_resampled, y_train_pos_resampled = X_train_positives, y_train_positives\n",
    "\n",
    "# Use extreme class weights to favor class 1 (minority class)\n",
    "positive_weights = {0: 8.0, 1: 1.0}  # Much higher weight for class 1 (which is class 0 after adjustment)\n",
    "print(f\"Positive cases model class weights: {positive_weights}\")\n",
    "\n",
    "# Initialize second stage model with strong focus on class 1\n",
    "positive_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,  # Lower learning rate for better generalization\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    class_weights=positive_weights,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train positive cases model on resampled data\n",
    "positive_model.fit(X_train_pos_resampled, y_train_pos_resampled)\n",
    "\n",
    "# Extract actual positive cases from test set for evaluation\n",
    "mask_test_actual_positives = y_test > 0\n",
    "X_test_actual_positives = X_test[mask_test_actual_positives]\n",
    "y_test_actual_positives = y_test[mask_test_actual_positives] - 1\n",
    "\n",
    "# Get predictions on actual positive cases\n",
    "positive_probs = positive_model.predict_proba(X_test_actual_positives)\n",
    "\n",
    "# Try 5 different thresholds focused on class 1 recall\n",
    "thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "best_recalls = (0, 0)\n",
    "\n",
    "print(\"\\n----- Testing thresholds for Stage 2 model -----\")\n",
    "for threshold in thresholds:\n",
    "    # For class 1 (which is 0 after adjustment), if prob < threshold, predict class 1\n",
    "    # This means we're making it easier to predict class 1\n",
    "    positive_preds = (positive_probs[:, 0] >= threshold).astype(int)  # Lower threshold for class 1\n",
    "    positive_preds = 1 - positive_preds  # Invert to make 0 = class 1 (original class 1) and 1 = class 2 (original class 2)\n",
    "    \n",
    "    recall_0 = recall_score(y_test_actual_positives == 0, positive_preds == 0)\n",
    "    recall_1 = recall_score(y_test_actual_positives == 1, positive_preds == 1)\n",
    "    f1 = (recall_0 * 0.7 + recall_1 * 0.3)  # Weighted toward class 1 recall\n",
    "    \n",
    "    print(f\"Threshold {threshold:.2f}: Class 1 recall: {recall_0:.4f}, Class 2 recall: {recall_1:.4f}, Combined: {f1:.4f}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_recalls = (recall_0, recall_1)\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.2f} with recalls - Class 1: {best_recalls[0]:.4f}, Class 2: {best_recalls[1]:.4f}\")\n",
    "\n",
    "# Apply best threshold for final model\n",
    "positive_threshold = best_threshold\n",
    "\n",
    "# Function to make hierarchical predictions with the optimized thresholds\n",
    "def hierarchical_predict(X, binary_model, positive_model, binary_threshold=0.2, positive_threshold=0.3):\n",
    "    # Stage 1: Predict if diabetes (class 1 or 2) or not (class 0)\n",
    "    binary_probs = binary_model.predict_proba(X)[:, 1]\n",
    "    binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "    \n",
    "    # Initialize with all zeros\n",
    "    final_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Find samples predicted as positive (1 or 2)\n",
    "    positive_indices = np.where(binary_preds == 1)[0]\n",
    "    \n",
    "    if len(positive_indices) > 0:\n",
    "        # Stage 2: For positive predictions, determine if class 1 or 2\n",
    "        X_positives = X.iloc[positive_indices] if hasattr(X, 'iloc') else X[positive_indices]\n",
    "        \n",
    "        # Get probabilities for the adjusted classes (0=class1, 1=class2)\n",
    "        positive_probs = positive_model.predict_proba(X_positives)\n",
    "        \n",
    "        # Apply inverted threshold: if prob of class1 (adjusted 0) >= threshold, predict class 1, else class 2\n",
    "        # This prioritizes class 1 prediction\n",
    "        positive_preds = (positive_probs[:, 0] >= positive_threshold).astype(int)\n",
    "        \n",
    "        # Convert back from [0,1] to [1,2] with the meaning that 0 means class 1, 1 means class 2\n",
    "        positive_preds = positive_preds * 0 + (1 - positive_preds) * 1 + 1\n",
    "        \n",
    "        # Assign to final predictions\n",
    "        final_preds[positive_indices] = positive_preds\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# Make hierarchical predictions with optimized thresholds\n",
    "y_pred_hierarchical = hierarchical_predict(\n",
    "    X_test, binary_model, positive_model, \n",
    "    binary_threshold=binary_threshold, \n",
    "    positive_threshold=positive_threshold\n",
    ")\n",
    "\n",
    "# Evaluate final hierarchical model\n",
    "print(\"\\n----- Combined Hierarchical Model Evaluation -----\")\n",
    "print(classification_report(y_test, y_pred_hierarchical))\n",
    "\n",
    "# Class-specific recall analysis\n",
    "print(\"\\nClass-specific Recall for Hierarchical Model:\")\n",
    "for cls in range(3):\n",
    "    if cls in np.unique(y_test):\n",
    "        recall = recall_score(y_test == cls, y_pred_hierarchical == cls)\n",
    "        print(f\"Class {cls} Recall: {recall:.4f}\")\n",
    "\n",
    "# Save the optimized models\n",
    "binary_model.save_model('catboost_binary_diabetes_optimized.cbm')\n",
    "positive_model.save_model('catboost_positive_diabetes_optimized.cbm')\n",
    "\n",
    "# Create a function to apply the optimized hierarchical model to new data\n",
    "def predict_diabetes_severity(X_new, binary_model_path='catboost_binary_diabetes_optimized.cbm', \n",
    "                             positive_model_path='catboost_positive_diabetes_optimized.cbm',\n",
    "                             binary_threshold=0.2, positive_threshold=best_threshold):\n",
    "    \"\"\"\n",
    "    Predict diabetes severity for new data using the optimized hierarchical model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : DataFrame or array\n",
    "        New features to predict on\n",
    "    binary_model_path : str\n",
    "        Path to saved binary model\n",
    "    positive_model_path : str\n",
    "        Path to saved positive cases model\n",
    "    binary_threshold : float\n",
    "        Threshold for binary model\n",
    "    positive_threshold : float\n",
    "        Threshold for positive cases model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0 = no diabetes, 1 = moderate diabetes, 2 = severe diabetes\n",
    "    \"\"\"\n",
    "    # Load models\n",
    "    binary_model = CatBoostClassifier()\n",
    "    binary_model.load_model(binary_model_path)\n",
    "    \n",
    "    positive_model = CatBoostClassifier()\n",
    "    positive_model.load_model(positive_model_path)\n",
    "    \n",
    "    # Make predictions with optimized thresholds\n",
    "    return hierarchical_predict(X_new, binary_model, positive_model, \n",
    "                               binary_threshold, positive_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012\n",
       "0.0    213703\n",
       "2.0     35346\n",
       "1.0      4631\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diabetes_012'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in full dataset:\n",
      "Class 0: 213703 samples (84.24%)\n",
      "Class 1: 4631 samples (1.83%)\n",
      "Class 2: 35346 samples (13.93%)\n",
      "Class distribution in training set: [170962   3705  28277]\n",
      "Binary class distribution in training set: [170962  31982]\n",
      "Binary model class weights: {0: 1.0, 1: 3.0}\n",
      "0:\tlearn: 0.6799525\ttest: 0.6801143\tbest: 0.6801143 (0)\ttotal: 45.8ms\tremaining: 45.8s\n",
      "100:\tlearn: 0.4903567\ttest: 0.4944139\tbest: 0.4944139 (100)\ttotal: 4.77s\tremaining: 42.4s\n",
      "200:\tlearn: 0.4851599\ttest: 0.4905256\tbest: 0.4905256 (200)\ttotal: 9.06s\tremaining: 36s\n",
      "300:\tlearn: 0.4828744\ttest: 0.4894473\tbest: 0.4894473 (300)\ttotal: 13.7s\tremaining: 31.8s\n",
      "400:\tlearn: 0.4809362\ttest: 0.4889510\tbest: 0.4889507 (399)\ttotal: 20.2s\tremaining: 30.1s\n",
      "500:\tlearn: 0.4788907\ttest: 0.4886254\tbest: 0.4886208 (499)\ttotal: 25.8s\tremaining: 25.7s\n",
      "600:\tlearn: 0.4769740\ttest: 0.4885239\tbest: 0.4885195 (593)\ttotal: 31.5s\tremaining: 20.9s\n",
      "700:\tlearn: 0.4752559\ttest: 0.4884828\tbest: 0.4884754 (698)\ttotal: 36.4s\tremaining: 15.5s\n",
      "800:\tlearn: 0.4737085\ttest: 0.4885121\tbest: 0.4884715 (706)\ttotal: 41.1s\tremaining: 10.2s\n",
      "900:\tlearn: 0.4722247\ttest: 0.4885146\tbest: 0.4884527 (827)\ttotal: 46.1s\tremaining: 5.07s\n",
      "999:\tlearn: 0.4708347\ttest: 0.4886060\tbest: 0.4884527 (827)\ttotal: 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4884526544\n",
      "bestIteration = 827\n",
      "\n",
      "Shrink model to first 828 iterations.\n",
      "\n",
      "----- Stage 1 Binary Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.52      0.68     42741\n",
      "           1       0.26      0.92      0.41      7995\n",
      "\n",
      "    accuracy                           0.59     50736\n",
      "   macro avg       0.62      0.72      0.55     50736\n",
      "weighted avg       0.86      0.59      0.64     50736\n",
      "\n",
      "Recall for positive cases (1 or 2): 0.9157\n",
      "\n",
      "Class distribution in positive cases (training): [ 3705 28277]\n",
      "Natural class priors: [0.11584641 0.88415359]\n",
      "Adjusted class priors: [0.8 0.2]\n",
      "\n",
      "----- Naive Bayes Threshold Exploration -----\n",
      "Threshold 0.25: Class 1 recall: 0.5745, Class 2 recall: 0.5712, Balanced score: 0.5729\n",
      "Threshold 0.20: Class 1 recall: 0.5324, Class 2 recall: 0.6107, Balanced score: 0.5715\n",
      "Threshold 0.30: Class 1 recall: 0.6048, Class 2 recall: 0.5367, Balanced score: 0.5707\n",
      "Threshold 0.15: Class 1 recall: 0.4816, Class 2 recall: 0.6594, Balanced score: 0.5705\n",
      "Threshold 0.40: Class 1 recall: 0.6577, Class 2 recall: 0.4818, Balanced score: 0.5697\n",
      "\n",
      "Best threshold: 0.25\n",
      "\n",
      "----- Stage 2 Naive Bayes Evaluation (on actual positives) -----\n",
      "Standard predictions:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.70      0.23       926\n",
      "         1.0       0.92      0.43      0.59      7069\n",
      "\n",
      "    accuracy                           0.47      7995\n",
      "   macro avg       0.53      0.57      0.41      7995\n",
      "weighted avg       0.83      0.47      0.55      7995\n",
      "\n",
      "\n",
      "Threshold-optimized predictions:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.57      0.24       926\n",
      "         1.0       0.91      0.57      0.70      7069\n",
      "\n",
      "    accuracy                           0.57      7995\n",
      "   macro avg       0.53      0.57      0.47      7995\n",
      "weighted avg       0.82      0.57      0.65      7995\n",
      "\n",
      "\n",
      "----- Combined Hierarchical Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.52      0.68     42741\n",
      "         1.0       0.02      0.42      0.04       926\n",
      "         2.0       0.35      0.57      0.44      7069\n",
      "\n",
      "    accuracy                           0.53     50736\n",
      "   macro avg       0.45      0.50      0.39     50736\n",
      "weighted avg       0.87      0.53      0.64     50736\n",
      "\n",
      "\n",
      "Class-specific Recall for Hierarchical Model:\n",
      "Class 0 Recall: 0.5244\n",
      "Class 1 Recall: 0.4168\n",
      "Class 2 Recall: 0.5705\n",
      "\n",
      "----- Top 10 Important Features for Severity Classification -----\n",
      "               Feature  Importance\n",
      "23  GenHlth_X_PhysHlth    8.099367\n",
      "21           BMI_X_Age    3.200815\n",
      "15            PhysHlth    1.681619\n",
      "25        Age_X_HighBP    1.283986\n",
      "27      Age_X_DiffWalk    0.970400\n",
      "26  Income_X_Education    0.941752\n",
      "32     risk_score_mult    0.923766\n",
      "30     condition_count    0.385981\n",
      "13             GenHlth    0.312469\n",
      "18                 Age    0.292852\n",
      "\n",
      "Models saved.\n",
      "\n",
      "Example usage of prediction function:\n",
      "predictions = predict_diabetes_severity(new_data)\n",
      "\n",
      "----- Precision at Different Thresholds -----\n",
      "Threshold 0.10: Class 1 precision: 0.1610, Class 2 precision: 0.9035\n",
      "Threshold 0.15: Class 1 precision: 0.1563, Class 2 precision: 0.9066\n",
      "Threshold 0.20: Class 1 precision: 0.1519, Class 2 precision: 0.9088\n",
      "Threshold 0.25: Class 1 precision: 0.1493, Class 2 precision: 0.9111\n",
      "Threshold 0.30: Class 1 precision: 0.1460, Class 2 precision: 0.9120\n",
      "Threshold 0.35: Class 1 precision: 0.1431, Class 2 precision: 0.9125\n",
      "Threshold 0.40: Class 1 precision: 0.1426, Class 2 precision: 0.9149\n",
      "Threshold 0.45: Class 1 precision: 0.1406, Class 2 precision: 0.9154\n",
      "Threshold 0.50: Class 1 precision: 0.1395, Class 2 precision: 0.9170\n",
      "Threshold 0.55: Class 1 precision: 0.1374, Class 2 precision: 0.9169\n",
      "Threshold 0.60: Class 1 precision: 0.1365, Class 2 precision: 0.9189\n",
      "Threshold 0.65: Class 1 precision: 0.1348, Class 2 precision: 0.9192\n",
      "Threshold 0.70: Class 1 precision: 0.1322, Class 2 precision: 0.9178\n",
      "Threshold 0.75: Class 1 precision: 0.1314, Class 2 precision: 0.9193\n",
      "Threshold 0.80: Class 1 precision: 0.1301, Class 2 precision: 0.9201\n",
      "Threshold 0.85: Class 1 precision: 0.1295, Class 2 precision: 0.9234\n",
      "Threshold 0.90: Class 1 precision: 0.1285, Class 2 precision: 0.9283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df = pd.read_csv(r'D:\\PIMA\\data_2\\cleaned_3.csv')\n",
    "\n",
    "# Drop any unnecessary columns\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = df['Diabetes_012']\n",
    "X = df.drop('Diabetes_012',axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Get the actual class distribution\n",
    "class_counts = np.bincount(y.astype(int))\n",
    "print(f\"Class distribution in full dataset:\")\n",
    "for cls, count in enumerate(class_counts):\n",
    "    print(f\"Class {cls}: {count} samples ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Create binary target for first stage model (0 vs [1,2])\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X, y, y_binary, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"Binary class distribution in training set: {np.bincount(y_binary_train)}\")\n",
    "\n",
    "# ----- STAGE 1: Binary Classification Model (0 vs [1,2]) -----\n",
    "\n",
    "# Calculate class weights for binary model - use weights that worked well previously\n",
    "binary_weights = {0: 1.0, 1: 3.0}  # Adjust if needed based on performance\n",
    "print(f\"Binary model class weights: {binary_weights}\")\n",
    "\n",
    "# Initialize first stage model (binary classifier)\n",
    "binary_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    class_weights=binary_weights,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train binary model\n",
    "binary_model.fit(X_train, y_binary_train, eval_set=(X_test, y_binary_test))\n",
    "\n",
    "# Get predictions from binary model\n",
    "binary_probs = binary_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply threshold to binary model\n",
    "binary_threshold = 0.2  # Adjust based on your preferred recall/precision balance\n",
    "binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "\n",
    "# Evaluate binary model\n",
    "print(\"\\n----- Stage 1 Binary Model Evaluation -----\")\n",
    "print(classification_report(y_binary_test, binary_preds))\n",
    "print(f\"Recall for positive cases (1 or 2): {recall_score(y_binary_test, binary_preds):.4f}\")\n",
    "\n",
    "# ----- STAGE 2: Naive Bayes for Severity Classification (1 vs 2) -----\n",
    "\n",
    "# Filter training data to include only classes 1 and 2\n",
    "mask_train = y_train > 0\n",
    "X_train_positives = X_train[mask_train]\n",
    "y_train_positives = y_train[mask_train] - 1  # Adjust to 0 (was 1) and 1 (was 2)\n",
    "\n",
    "print(f\"\\nClass distribution in positive cases (training): {np.bincount(y_train_positives.astype(int))}\")\n",
    "\n",
    "# Initialize Naive Bayes model for severity classification\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# We can adjust the prior probabilities to account for class imbalance\n",
    "# Calculate class distribution in positive cases\n",
    "pos_class_counts = np.bincount(y_train_positives.astype(int))\n",
    "pos_class_priors = pos_class_counts / pos_class_counts.sum()\n",
    "\n",
    "# You can adjust priors to give more weight to the minority class (class 1)\n",
    "# For example, you might want a 60/40 or 70/30 prior instead of the actual distribution\n",
    "adjusted_priors = np.array([0.8, 0.2])  # Adjusted to give more weight to class 1 (40% vs actual ~10%)\n",
    "print(f\"Natural class priors: {pos_class_priors}\")\n",
    "print(f\"Adjusted class priors: {adjusted_priors}\")\n",
    "\n",
    "# Set the adjusted priors (comment this out to use natural priors)\n",
    "nb_model.priors = adjusted_priors\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model.fit(X_train_positives, y_train_positives)\n",
    "\n",
    "# Extract actual positive cases from test set for evaluation\n",
    "mask_test_actual_positives = y_test > 0\n",
    "X_test_actual_positives = X_test[mask_test_actual_positives]\n",
    "y_test_actual_positives = y_test[mask_test_actual_positives] - 1  # Adjust to 0 and 1\n",
    "\n",
    "# Get predictions on actual positive cases\n",
    "nb_probs = nb_model.predict_proba(X_test_actual_positives)\n",
    "nb_preds = nb_model.predict(X_test_actual_positives)\n",
    "\n",
    "# Function to explore different probability thresholds\n",
    "def try_probability_thresholds(probs, y_true):\n",
    "    results = []\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)  # Test 17 thresholds\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Predict class 1 (severe) if probability > threshold\n",
    "        preds = (probs[:, 1] >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class0_recall = recall_score(y_true == 0, preds == 0)\n",
    "        class1_recall = recall_score(y_true == 1, preds == 1)\n",
    "        \n",
    "        # Balanced score (equal weight to both classes)\n",
    "        balanced_score = (class0_recall + class1_recall) / 2\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'class1_recall': class0_recall,  # This is original class 1 (moderate)\n",
    "            'class2_recall': class1_recall,  # This is original class 2 (severe)\n",
    "            'balanced_score': balanced_score\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Try different thresholds\n",
    "threshold_results = try_probability_thresholds(nb_probs, y_test_actual_positives)\n",
    "\n",
    "# Print top 5 thresholds by balanced score\n",
    "print(\"\\n----- Naive Bayes Threshold Exploration -----\")\n",
    "for result in sorted(threshold_results, key=lambda x: x['balanced_score'], reverse=True)[:5]:\n",
    "    print(f\"Threshold {result['threshold']:.2f}: \"\n",
    "          f\"Class 1 recall: {result['class1_recall']:.4f}, \"\n",
    "          f\"Class 2 recall: {result['class2_recall']:.4f}, \"\n",
    "          f\"Balanced score: {result['balanced_score']:.4f}\")\n",
    "\n",
    "# Find best threshold\n",
    "best_result = max(threshold_results, key=lambda x: x['balanced_score'])\n",
    "nb_threshold = best_result['threshold']\n",
    "print(f\"\\nBest threshold: {nb_threshold:.2f}\")\n",
    "\n",
    "# Apply threshold to get final predictions\n",
    "nb_preds_threshold = (nb_probs[:, 1] >= nb_threshold).astype(int)\n",
    "\n",
    "# Evaluate Naive Bayes model with best threshold\n",
    "print(\"\\n----- Stage 2 Naive Bayes Evaluation (on actual positives) -----\")\n",
    "print(\"Standard predictions:\")\n",
    "print(classification_report(y_test_actual_positives, nb_preds))\n",
    "print(\"\\nThreshold-optimized predictions:\")\n",
    "print(classification_report(y_test_actual_positives, nb_preds_threshold))\n",
    "\n",
    "# Function to make hierarchical predictions\n",
    "def hierarchical_predict(X, binary_model, nb_model, binary_threshold=0.3, nb_threshold=0.5):\n",
    "    # Stage 1: Binary classification\n",
    "    binary_probs = binary_model.predict_proba(X)[:, 1]\n",
    "    binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "    \n",
    "    # Initialize with all zeros\n",
    "    final_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Find samples predicted as positive (1 or 2)\n",
    "    positive_indices = np.where(binary_preds == 1)[0]\n",
    "    \n",
    "    if len(positive_indices) > 0:\n",
    "        # Stage 2: For positive predictions, determine severity\n",
    "        if hasattr(X, 'iloc'):\n",
    "            X_positives = X.iloc[positive_indices]\n",
    "        else:\n",
    "            X_positives = X[positive_indices]\n",
    "        \n",
    "        # Get probabilities from Naive Bayes\n",
    "        nb_probs = nb_model.predict_proba(X_positives)\n",
    "        \n",
    "        # Apply threshold\n",
    "        nb_preds = (nb_probs[:, 1] >= nb_threshold).astype(int)\n",
    "        \n",
    "        # Convert back from [0,1] to [1,2]\n",
    "        severity_preds = nb_preds + 1\n",
    "        \n",
    "        # Assign to final predictions\n",
    "        final_preds[positive_indices] = severity_preds\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# Make hierarchical predictions\n",
    "y_pred_hierarchical = hierarchical_predict(\n",
    "    X_test, binary_model, nb_model, \n",
    "    binary_threshold=binary_threshold, \n",
    "    nb_threshold=nb_threshold\n",
    ")\n",
    "\n",
    "# Evaluate final hierarchical model\n",
    "print(\"\\n----- Combined Hierarchical Model Evaluation -----\")\n",
    "print(classification_report(y_test, y_pred_hierarchical))\n",
    "\n",
    "# Class-specific recall analysis\n",
    "print(\"\\nClass-specific Recall for Hierarchical Model:\")\n",
    "for cls in range(3):\n",
    "    if cls in np.unique(y_test):\n",
    "        recall = recall_score(y_test == cls, y_pred_hierarchical == cls)\n",
    "        print(f\"Class {cls} Recall: {recall:.4f}\")\n",
    "\n",
    "# Feature importance analysis for Naive Bayes\n",
    "def get_naive_bayes_feature_importance(nb_model, feature_names):\n",
    "    # For Gaussian Naive Bayes, we can look at the difference in means between classes\n",
    "    # as an indication of feature importance\n",
    "    mean_diff = np.abs(nb_model.theta_[1] - nb_model.theta_[0])\n",
    "    \n",
    "    # Create a DataFrame with feature names and importance scores\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': mean_diff\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    return importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Get feature importance for Naive Bayes\n",
    "nb_importance = get_naive_bayes_feature_importance(nb_model, X.columns)\n",
    "print(\"\\n----- Top 10 Important Features for Severity Classification -----\")\n",
    "print(nb_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = nb_importance.head(15)\n",
    "plt.barh(top_features['Feature'][::-1], top_features['Importance'][::-1])\n",
    "plt.xlabel('Importance (Mean Difference Between Classes)')\n",
    "plt.title('Top 15 Features for Distinguishing Diabetes Severity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('naive_bayes_feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the models\n",
    "binary_model.save_model('catboost_binary_diabetes.cbm')\n",
    "import joblib\n",
    "joblib.dump(nb_model, 'naive_bayes_severity.joblib')\n",
    "print(\"\\nModels saved.\")\n",
    "\n",
    "# Create a function for making predictions on new data\n",
    "def predict_diabetes_severity(X_new, binary_model_path='catboost_binary_diabetes.cbm', \n",
    "                             nb_model_path='naive_bayes_severity.joblib',\n",
    "                             binary_threshold=0.3, nb_threshold=nb_threshold):\n",
    "    \"\"\"\n",
    "    Predict diabetes severity for new data using the hierarchical model.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0 = no diabetes, 1 = moderate diabetes, 2 = severe diabetes\n",
    "    \"\"\"\n",
    "    # Load models\n",
    "    binary_model = CatBoostClassifier()\n",
    "    binary_model.load_model(binary_model_path)\n",
    "    \n",
    "    nb_model = joblib.load(nb_model_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    return hierarchical_predict(X_new, binary_model, nb_model, \n",
    "                               binary_threshold, nb_threshold)\n",
    "\n",
    "print(\"\\nExample usage of prediction function:\")\n",
    "print(\"predictions = predict_diabetes_severity(new_data)\")\n",
    "\n",
    "# Let's also check how well we're doing on precision for each class\n",
    "def get_precision_by_threshold(probs, y_true):\n",
    "    from sklearn.metrics import precision_score\n",
    "    \n",
    "    results = []\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        preds = (probs[:, 1] >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate precision when available (handle division by zero)\n",
    "        try:\n",
    "            class0_precision = precision_score(y_true == 0, preds == 0)\n",
    "        except:\n",
    "            class0_precision = 0\n",
    "            \n",
    "        try:\n",
    "            class1_precision = precision_score(y_true == 1, preds == 1)\n",
    "        except:\n",
    "            class1_precision = 0\n",
    "        \n",
    "        # F1-like score that balances recall and precision\n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'class1_precision': class0_precision,\n",
    "            'class2_precision': class1_precision\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Check precision at different thresholds\n",
    "precision_results = get_precision_by_threshold(nb_probs, y_test_actual_positives)\n",
    "\n",
    "print(\"\\n----- Precision at Different Thresholds -----\")\n",
    "for result in precision_results:\n",
    "    print(f\"Threshold {result['threshold']:.2f}: \"\n",
    "          f\"Class 1 precision: {result['class1_precision']:.4f}, \"\n",
    "          f\"Class 2 precision: {result['class2_precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available features: ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income', 'BMI_X_Age', 'HighBP_X_HighChol', 'GenHlth_X_PhysHlth', 'BMI_X_PhysActivity', 'Age_X_HighBP', 'Income_X_Education', 'Age_X_DiffWalk', 'health_bp_decay', 'low_ses', 'condition_count', 'health_cluster', 'risk_score_mult']\n",
      "Class distribution in training set: [170962   3705  28277]\n",
      "Binary class distribution in training set: [170962  31982]\n",
      "0:\tlearn: 0.6715087\ttest: 0.6717505\tbest: 0.6717505 (0)\ttotal: 48.1ms\tremaining: 48.1s\n",
      "100:\tlearn: 0.4861871\ttest: 0.4910353\tbest: 0.4910353 (100)\ttotal: 4.97s\tremaining: 44.2s\n",
      "200:\tlearn: 0.4823351\ttest: 0.4892199\tbest: 0.4892199 (200)\ttotal: 9.73s\tremaining: 38.7s\n",
      "300:\tlearn: 0.4789850\ttest: 0.4885578\tbest: 0.4885550 (294)\ttotal: 14.1s\tremaining: 32.8s\n",
      "400:\tlearn: 0.4758785\ttest: 0.4884815\tbest: 0.4884253 (365)\ttotal: 18.7s\tremaining: 27.9s\n",
      "500:\tlearn: 0.4733099\ttest: 0.4883799\tbest: 0.4883340 (437)\ttotal: 24.4s\tremaining: 24.3s\n",
      "600:\tlearn: 0.4708122\ttest: 0.4886007\tbest: 0.4883340 (437)\ttotal: 30s\tremaining: 19.9s\n",
      "700:\tlearn: 0.4686286\ttest: 0.4888152\tbest: 0.4883340 (437)\ttotal: 36s\tremaining: 15.3s\n",
      "800:\tlearn: 0.4663974\ttest: 0.4890742\tbest: 0.4883340 (437)\ttotal: 41.2s\tremaining: 10.2s\n",
      "900:\tlearn: 0.4643491\ttest: 0.4893681\tbest: 0.4883340 (437)\ttotal: 46.7s\tremaining: 5.13s\n",
      "999:\tlearn: 0.4624104\ttest: 0.4896408\tbest: 0.4883340 (437)\ttotal: 51.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4883339852\n",
      "bestIteration = 437\n",
      "\n",
      "Shrink model to first 438 iterations.\n",
      "\n",
      "----- Stage 1 Binary Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.52      0.68     42741\n",
      "           1       0.26      0.92      0.41      7995\n",
      "\n",
      "    accuracy                           0.59     50736\n",
      "   macro avg       0.62      0.72      0.55     50736\n",
      "weighted avg       0.86      0.59      0.64     50736\n",
      "\n",
      "Recall for positive cases (1 or 2): 0.9154\n",
      "\n",
      "----- Severity Threshold Evaluation -----\n",
      "Threshold 1:\n",
      "  Class 1 recall: 0.2063\n",
      "  Class 2 recall: 0.8827\n",
      "  Average recall: 0.5445\n",
      "  Score distribution: [1020 1750 1579 1228  965  634  393  252  111   63]\n",
      "Threshold 2:\n",
      "  Class 1 recall: 0.4406\n",
      "  Class 2 recall: 0.6659\n",
      "  Average recall: 0.5532\n",
      "  Score distribution: [1020 1750 1579 1228  965  634  393  252  111   63]\n",
      "Threshold 3:\n",
      "  Class 1 recall: 0.6663\n",
      "  Class 2 recall: 0.4721\n",
      "  Average recall: 0.5692\n",
      "  Score distribution: [1020 1750 1579 1228  965  634  393  252  111   63]\n",
      "Threshold 4:\n",
      "  Class 1 recall: 0.7937\n",
      "  Class 2 recall: 0.3150\n",
      "  Average recall: 0.5544\n",
      "  Score distribution: [1020 1750 1579 1228  965  634  393  252  111   63]\n",
      "Threshold 5:\n",
      "  Class 1 recall: 0.8834\n",
      "  Class 2 recall: 0.1903\n",
      "  Average recall: 0.5368\n",
      "  Score distribution: [1020 1750 1579 1228  965  634  393  252  111   63]\n",
      "\n",
      "Best severity threshold: 3\n",
      "\n",
      "----- Combined Hierarchical Model Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.52      0.68     42741\n",
      "         1.0       0.03      0.51      0.05       926\n",
      "         2.0       0.34      0.47      0.40      7069\n",
      "\n",
      "    accuracy                           0.52     50736\n",
      "   macro avg       0.45      0.50      0.38     50736\n",
      "weighted avg       0.87      0.52      0.63     50736\n",
      "\n",
      "\n",
      "Class-specific Recall for Hierarchical Model:\n",
      "Class 0 Recall: 0.5235\n",
      "Class 1 Recall: 0.5140\n",
      "Class 2 Recall: 0.4699\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22373 14334  6034]\n",
      " [  146   476   304]\n",
      " [  530  3217  3322]]\n",
      "\n",
      "Severity Score Distribution for Class 1:\n",
      "[0.2062635  0.23434125 0.22570194 0.12742981 0.08963283 0.05399568\n",
      " 0.0399568  0.01187905 0.00647948 0.00431965]\n",
      "\n",
      "Severity Score Distribution for Class 2:\n",
      "[0.1172726  0.21686236 0.19380393 0.15702362 0.12477012 0.08261423\n",
      " 0.05036073 0.03409252 0.01485359 0.0083463 ]\n",
      "\n",
      "Example usage of prediction function:\n",
      "predictions = predict_diabetes_severity(new_data)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display column names for reference\n",
    "print(\"Available features:\", X.columns.tolist())\n",
    "\n",
    "# Create binary target for first stage model (0 vs [1,2])\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X, y, y_binary, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Class distribution in training set: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"Binary class distribution in training set: {np.bincount(y_binary_train)}\")\n",
    "\n",
    "# ----- STAGE 1: Binary Classification Model (0 vs [1,2]) -----\n",
    "\n",
    "# Initialize first stage model (binary classifier)\n",
    "binary_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    class_weights={0: 1.0, 1: 3.0},\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Train binary model\n",
    "binary_model.fit(X_train, y_binary_train, eval_set=(X_test, y_binary_test))\n",
    "\n",
    "# Get predictions from binary model\n",
    "binary_probs = binary_model.predict_proba(X_test)[:, 1]\n",
    "binary_threshold = 0.2 # Use the threshold that gave good recall\n",
    "binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "\n",
    "# Evaluate binary model\n",
    "print(\"\\n----- Stage 1 Binary Model Evaluation -----\")\n",
    "print(classification_report(y_binary_test, binary_preds))\n",
    "print(f\"Recall for positive cases (1 or 2): {recall_score(y_binary_test, binary_preds):.4f}\")\n",
    "\n",
    "# ----- STAGE 2: Deterministic Rules for Severity Classification -----\n",
    "\n",
    "# Define deterministic rules function\n",
    "def determine_diabetes_severity(X):\n",
    "    \"\"\"\n",
    "    Apply clinical rules to determine diabetes severity (class 1 or 2)\n",
    "    \n",
    "    Rules are based on comorbidities and risk factors from the BRFSS dataset\n",
    "    Returns 1 for moderate diabetes, 2 for severe diabetes\n",
    "    \"\"\"\n",
    "    # Initialize severity scores\n",
    "    severity_scores = np.zeros(len(X))\n",
    "    \n",
    "    # Rule 1: Heart disease or stroke indicates severe diabetes\n",
    "    if 'HeartDiseaseorAttack' in X.columns:\n",
    "        severity_scores += (X['HeartDiseaseorAttack'] == 1).astype(int) * 2\n",
    "    \n",
    "    if 'Stroke' in X.columns:\n",
    "        severity_scores += (X['Stroke'] == 1).astype(int) * 2\n",
    "    \n",
    "    # Rule 2: BMI > 35 indicates higher severity\n",
    "    if 'BMI' in X.columns:\n",
    "        severity_scores += (X['BMI'] > 35).astype(int)\n",
    "    \n",
    "    # Rule 3: Poor physical health indicates complications\n",
    "    if 'PhysHlth' in X.columns:\n",
    "        severity_scores += (X['PhysHlth'] > 14).astype(int)  # More than 2 weeks of poor health\n",
    "    \n",
    "    # Rule 4: Combination of high blood pressure and high cholesterol\n",
    "    if 'HighBP' in X.columns and 'HighChol' in X.columns:\n",
    "        severity_scores += ((X['HighBP'] == 1) & (X['HighChol'] == 1)).astype(int)\n",
    "    \n",
    "    # Rule 5: Difficulty walking/climbing stairs indicates complications\n",
    "    if 'DiffWalk' in X.columns:\n",
    "        severity_scores += (X['DiffWalk'] == 1).astype(int)\n",
    "    \n",
    "    # Rule 6: Age-related severity (older age â†’ higher risk of complications)\n",
    "    if 'Age' in X.columns:\n",
    "        severity_scores += (X['Age'] >= 10).astype(int)  # Age â‰¥ 65 (Age column is categorical in BRFSS)\n",
    "    \n",
    "    # Rule 7: Poor general health \n",
    "    if 'GenHlth' in X.columns:\n",
    "        severity_scores += (X['GenHlth'] >= 4).astype(int)  # Fair or poor health\n",
    "    \n",
    "    # Classify based on severity score\n",
    "    # Tunable threshold - this value determines the split between class 1 and 2\n",
    "    severity_threshold = 2\n",
    "    \n",
    "    # If score meets or exceeds threshold, classify as severe (class 2)\n",
    "    # Otherwise, classify as moderate (class 1)\n",
    "    severity_class = np.where(severity_scores >= severity_threshold, 2, 1)\n",
    "    \n",
    "    return severity_class\n",
    "\n",
    "# Define function to try different severity thresholds\n",
    "def evaluate_severity_thresholds(X, y, thresholds=[1, 2, 3, 4]):\n",
    "    \"\"\"Evaluate different severity score thresholds for class 1 vs 2 determination\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Extract only actual positive cases (class 1 or 2)\n",
    "    mask = y > 0\n",
    "    X_positives = X[mask]\n",
    "    y_positives = y[mask]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Set the severity threshold for the rules\n",
    "        severity_scores = np.zeros(len(X_positives))\n",
    "        \n",
    "        # Calculate severity scores (same logic as determine_diabetes_severity)\n",
    "        if 'HeartDiseaseorAttack' in X_positives.columns:\n",
    "            severity_scores += (X_positives['HeartDiseaseorAttack'] == 1).astype(int) * 2\n",
    "        \n",
    "        if 'Stroke' in X_positives.columns:\n",
    "            severity_scores += (X_positives['Stroke'] == 1).astype(int) * 2\n",
    "        \n",
    "        if 'BMI' in X_positives.columns:\n",
    "            severity_scores += (X_positives['BMI'] > 35).astype(int)\n",
    "        \n",
    "        if 'PhysHlth' in X_positives.columns:\n",
    "            severity_scores += (X_positives['PhysHlth'] > 14).astype(int)\n",
    "        \n",
    "        if 'HighBP' in X_positives.columns and 'HighChol' in X_positives.columns:\n",
    "            severity_scores += ((X_positives['HighBP'] == 1) & (X_positives['HighChol'] == 1)).astype(int)\n",
    "        \n",
    "        if 'DiffWalk' in X_positives.columns:\n",
    "            severity_scores += (X_positives['DiffWalk'] == 1).astype(int)\n",
    "        \n",
    "        if 'Age' in X_positives.columns:\n",
    "            severity_scores += (X_positives['Age'] >= 10).astype(int)  # Age â‰¥ 65\n",
    "        \n",
    "        if 'GenHlth' in X_positives.columns:\n",
    "            severity_scores += (X_positives['GenHlth'] >= 4).astype(int)\n",
    "        \n",
    "        # Apply threshold\n",
    "        y_pred = np.where(severity_scores >= threshold, 2, 1)\n",
    "        \n",
    "        # Calculate recalls for class 1 and 2\n",
    "        class1_recall = recall_score(y_positives == 1, y_pred == 1)\n",
    "        class2_recall = recall_score(y_positives == 2, y_pred == 2)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'class1_recall': class1_recall,\n",
    "            'class2_recall': class2_recall,\n",
    "            'avg_recall': (class1_recall + class2_recall) / 2,\n",
    "            'score_distribution': np.bincount(severity_scores.astype(int))\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate different severity thresholds\n",
    "threshold_results = evaluate_severity_thresholds(X_test, y_test, thresholds=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Print threshold evaluation results\n",
    "print(\"\\n----- Severity Threshold Evaluation -----\")\n",
    "for result in threshold_results:\n",
    "    print(f\"Threshold {result['threshold']}:\")\n",
    "    print(f\"  Class 1 recall: {result['class1_recall']:.4f}\")\n",
    "    print(f\"  Class 2 recall: {result['class2_recall']:.4f}\")\n",
    "    print(f\"  Average recall: {result['avg_recall']:.4f}\")\n",
    "    print(f\"  Score distribution: {result['score_distribution']}\")\n",
    "\n",
    "# Find best threshold\n",
    "best_threshold = max(threshold_results, key=lambda x: x['avg_recall'])['threshold']\n",
    "print(f\"\\nBest severity threshold: {best_threshold}\")\n",
    "\n",
    "# Function to make hierarchical predictions\n",
    "def hierarchical_predict(X, binary_model, binary_threshold=0.2, severity_threshold=1):\n",
    "    # Stage 1: Binary classification\n",
    "    binary_probs = binary_model.predict_proba(X)[:, 1]\n",
    "    binary_preds = (binary_probs >= binary_threshold).astype(int)\n",
    "    \n",
    "    # Initialize with all zeros\n",
    "    final_preds = np.zeros(len(X))\n",
    "    \n",
    "    # Find samples predicted as positive (1 or 2)\n",
    "    positive_indices = np.where(binary_preds == 1)[0]\n",
    "    \n",
    "    if len(positive_indices) > 0:\n",
    "        # Stage 2: For positive predictions, determine severity\n",
    "        if hasattr(X, 'iloc'):\n",
    "            X_positives = X.iloc[positive_indices]\n",
    "        else:\n",
    "            X_positives = X[positive_indices]\n",
    "        \n",
    "        # Apply deterministic rules\n",
    "        severity_scores = np.zeros(len(X_positives))\n",
    "        \n",
    "        # Calculate severity scores\n",
    "        if 'HeartDiseaseorAttack' in X_positives.columns:\n",
    "            severity_scores += (X_positives['HeartDiseaseorAttack'] == 1).astype(int) * 2\n",
    "        \n",
    "        if 'Stroke' in X_positives.columns:\n",
    "            severity_scores += (X_positives['Stroke'] == 1).astype(int) * 2\n",
    "        \n",
    "        if 'BMI' in X_positives.columns:\n",
    "            severity_scores += (X_positives['BMI'] > 35).astype(int)\n",
    "        \n",
    "        if 'PhysHlth' in X_positives.columns:\n",
    "            severity_scores += (X_positives['PhysHlth'] > 14).astype(int)\n",
    "        \n",
    "        if 'HighBP' in X_positives.columns and 'HighChol' in X_positives.columns:\n",
    "            severity_scores += ((X_positives['HighBP'] == 1) & (X_positives['HighChol'] == 1)).astype(int)\n",
    "        \n",
    "        if 'DiffWalk' in X_positives.columns:\n",
    "            severity_scores += (X_positives['DiffWalk'] == 1).astype(int)\n",
    "        \n",
    "        if 'Age' in X_positives.columns:\n",
    "            severity_scores += (X_positives['Age'] >= 10).astype(int)\n",
    "        \n",
    "        if 'GenHlth' in X_positives.columns:\n",
    "            severity_scores += (X_positives['GenHlth'] >= 4).astype(int)\n",
    "        \n",
    "        # Apply threshold\n",
    "        severity_preds = np.where(severity_scores >= severity_threshold, 2, 1)\n",
    "        \n",
    "        # Assign to final predictions\n",
    "        final_preds[positive_indices] = severity_preds\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# Make hierarchical predictions with best threshold\n",
    "y_pred_hierarchical = hierarchical_predict(\n",
    "    X_test, binary_model, \n",
    "    binary_threshold=binary_threshold, \n",
    "    severity_threshold=best_threshold\n",
    ")\n",
    "\n",
    "# Evaluate final hierarchical model\n",
    "print(\"\\n----- Combined Hierarchical Model Evaluation -----\")\n",
    "print(classification_report(y_test, y_pred_hierarchical))\n",
    "\n",
    "# Class-specific recall analysis\n",
    "print(\"\\nClass-specific Recall for Hierarchical Model:\")\n",
    "for cls in range(3):\n",
    "    if cls in np.unique(y_test):\n",
    "        recall = recall_score(y_test == cls, y_pred_hierarchical == cls)\n",
    "        print(f\"Class {cls} Recall: {recall:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_hierarchical)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Analyze severity score distribution for class 1 and 2\n",
    "mask_test_positives = y_test > 0\n",
    "X_test_positives = X_test[mask_test_positives]\n",
    "y_test_positives = y_test[mask_test_positives]\n",
    "\n",
    "# Calculate severity scores for all positive cases\n",
    "severity_scores = np.zeros(len(X_test_positives))\n",
    "\n",
    "if 'HeartDiseaseorAttack' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['HeartDiseaseorAttack'] == 1).astype(int) * 2\n",
    "\n",
    "if 'Stroke' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['Stroke'] == 1).astype(int) * 2\n",
    "\n",
    "if 'BMI' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['BMI'] > 35).astype(int)\n",
    "\n",
    "if 'PhysHlth' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['PhysHlth'] > 14).astype(int)\n",
    "\n",
    "if 'HighBP' in X_test_positives.columns and 'HighChol' in X_test_positives.columns:\n",
    "    severity_scores += ((X_test_positives['HighBP'] == 1) & (X_test_positives['HighChol'] == 1)).astype(int)\n",
    "\n",
    "if 'DiffWalk' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['DiffWalk'] == 1).astype(int)\n",
    "\n",
    "if 'Age' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['Age'] >= 10).astype(int)\n",
    "\n",
    "if 'GenHlth' in X_test_positives.columns:\n",
    "    severity_scores += (X_test_positives['GenHlth'] >= 4).astype(int)\n",
    "\n",
    "# Group by class and get score distribution\n",
    "class1_scores = severity_scores[y_test_positives == 1]\n",
    "class2_scores = severity_scores[y_test_positives == 2]\n",
    "\n",
    "print(\"\\nSeverity Score Distribution for Class 1:\")\n",
    "print(np.bincount(class1_scores.astype(int)) / len(class1_scores))\n",
    "\n",
    "print(\"\\nSeverity Score Distribution for Class 2:\")\n",
    "print(np.bincount(class2_scores.astype(int)) / len(class2_scores))\n",
    "\n",
    "# Save the binary model\n",
    "binary_model.save_model('catboost_binary_diabetes.cbm')\n",
    "\n",
    "# Create a standalone function for diabetes severity prediction\n",
    "def predict_diabetes_severity(X_new, binary_model_path='catboost_binary_diabetes.cbm', \n",
    "                             binary_threshold=0.2, severity_threshold=best_threshold):\n",
    "    \"\"\"\n",
    "    Predict diabetes status and severity using the hybrid model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : DataFrame\n",
    "        New features to predict on\n",
    "    binary_model_path : str\n",
    "        Path to saved binary model\n",
    "    binary_threshold : float\n",
    "        Threshold for binary model\n",
    "    severity_threshold : int\n",
    "        Threshold for severity rules\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0 = no diabetes, 1 = moderate diabetes, 2 = severe diabetes\n",
    "    \"\"\"\n",
    "    # Load binary model\n",
    "    binary_model = CatBoostClassifier()\n",
    "    binary_model.load_model(binary_model_path)\n",
    "    \n",
    "    # Make predictions using the hierarchical model\n",
    "    return hierarchical_predict(X_new, binary_model, binary_threshold, severity_threshold)\n",
    "\n",
    "print(\"\\nExample usage of prediction function:\")\n",
    "print(\"predictions = predict_diabetes_severity(new_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "Class 0: 170962 samples (84.24%)\n",
      "Class 1: 3705 samples (1.83%)\n",
      "Class 2: 28277 samples (13.93%)\n",
      "Subset 1 class distribution: [63964  3705 28277]\n",
      "Subset 2 class distribution: [63964  3705 28277]\n",
      "Subset 3 class distribution: [63964  3705 28277]\n",
      "Subset 4 class distribution: [63964  3705 28277]\n",
      "Subset 5 class distribution: [63964  3705 28277]\n",
      "\n",
      "Training model 1/5...\n",
      "0:\tlearn: 1.0547578\ttotal: 116ms\tremaining: 58s\n",
      "100:\tlearn: 0.5921423\ttotal: 5.3s\tremaining: 21s\n",
      "200:\tlearn: 0.5853564\ttotal: 9.55s\tremaining: 14.2s\n",
      "300:\tlearn: 0.5801343\ttotal: 14s\tremaining: 9.23s\n",
      "400:\tlearn: 0.5757723\ttotal: 18.1s\tremaining: 4.47s\n",
      "499:\tlearn: 0.5718670\ttotal: 22.3s\tremaining: 0us\n",
      "\n",
      "Model 1 performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     42741\n",
      "           1       0.00      0.00      0.00       926\n",
      "           2       0.40      0.55      0.46      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.44      0.47      0.45     50736\n",
      "weighted avg       0.82      0.81      0.81     50736\n",
      "\n",
      "\n",
      "Training model 2/5...\n",
      "0:\tlearn: 1.0545898\ttotal: 49.6ms\tremaining: 24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 0.5928815\ttotal: 4.85s\tremaining: 19.2s\n",
      "200:\tlearn: 0.5858318\ttotal: 8.95s\tremaining: 13.3s\n",
      "300:\tlearn: 0.5807847\ttotal: 13.3s\tremaining: 8.78s\n",
      "400:\tlearn: 0.5762521\ttotal: 17.5s\tremaining: 4.32s\n",
      "499:\tlearn: 0.5724593\ttotal: 21.8s\tremaining: 0us\n",
      "\n",
      "Model 2 performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     42741\n",
      "           1       0.00      0.00      0.00       926\n",
      "           2       0.40      0.55      0.46      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.44      0.47      0.45     50736\n",
      "weighted avg       0.82      0.81      0.81     50736\n",
      "\n",
      "\n",
      "Training model 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0547412\ttotal: 60.1ms\tremaining: 30s\n",
      "100:\tlearn: 0.5916045\ttotal: 5.01s\tremaining: 19.8s\n",
      "200:\tlearn: 0.5842809\ttotal: 9.41s\tremaining: 14s\n",
      "300:\tlearn: 0.5790827\ttotal: 14.1s\tremaining: 9.3s\n",
      "400:\tlearn: 0.5744641\ttotal: 18.6s\tremaining: 4.58s\n",
      "499:\tlearn: 0.5705095\ttotal: 24.5s\tremaining: 0us\n",
      "\n",
      "Model 3 performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     42741\n",
      "           1       0.00      0.00      0.00       926\n",
      "           2       0.40      0.56      0.46      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.44      0.48      0.45     50736\n",
      "weighted avg       0.82      0.81      0.81     50736\n",
      "\n",
      "\n",
      "Training model 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0541207\ttotal: 69.3ms\tremaining: 34.6s\n",
      "100:\tlearn: 0.5920090\ttotal: 7.96s\tremaining: 31.4s\n",
      "200:\tlearn: 0.5849939\ttotal: 16.3s\tremaining: 24.2s\n",
      "300:\tlearn: 0.5799839\ttotal: 23.8s\tremaining: 15.7s\n",
      "400:\tlearn: 0.5756543\ttotal: 28.4s\tremaining: 7.01s\n",
      "499:\tlearn: 0.5716707\ttotal: 32.8s\tremaining: 0us\n",
      "\n",
      "Model 4 performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     42741\n",
      "           1       0.00      0.00      0.00       926\n",
      "           2       0.40      0.56      0.46      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.44      0.48      0.45     50736\n",
      "weighted avg       0.82      0.81      0.81     50736\n",
      "\n",
      "\n",
      "Training model 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0553114\ttotal: 41.1ms\tremaining: 20.5s\n",
      "100:\tlearn: 0.5941558\ttotal: 4.94s\tremaining: 19.5s\n",
      "200:\tlearn: 0.5872655\ttotal: 9.41s\tremaining: 14s\n",
      "300:\tlearn: 0.5821000\ttotal: 13.6s\tremaining: 8.98s\n",
      "400:\tlearn: 0.5779081\ttotal: 17.6s\tremaining: 4.34s\n",
      "499:\tlearn: 0.5739701\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "Model 5 performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     42741\n",
      "           1       0.00      0.00      0.00       926\n",
      "           2       0.40      0.55      0.46      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.44      0.47      0.45     50736\n",
      "weighted avg       0.82      0.81      0.81     50736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PIMA\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 194\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.argmax(weighted_probas, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Evaluate ensemble with hard voting (majority vote)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m y_pred_hard = \u001b[43mensemble_predict_hard_voting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m----- Ensemble with Hard Voting -----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_hard))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mensemble_predict_hard_voting\u001b[39m\u001b[34m(models, X)\u001b[39m\n\u001b[32m    129\u001b[39m ensemble_predictions = np.zeros(\u001b[38;5;28mlen\u001b[39m(X))\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, preds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions):\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Count occurrences of each class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     votes = \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# Find class with most votes (majority)\u001b[39;00m\n\u001b[32m    136\u001b[39m     ensemble_predictions[i] = votes.most_common(\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\collections\\__init__.py:597\u001b[39m, in \u001b[36mCounter.__init__\u001b[39m\u001b[34m(self, iterable, **kwds)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[32m    587\u001b[39m \u001b[33;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[33;03mof elements to their counts.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    594\u001b[39m \n\u001b[32m    595\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\collections\\__init__.py:688\u001b[39m, in \u001b[36mCounter.update\u001b[39m\u001b[34m(self, iterable, **kwds)\u001b[39m\n\u001b[32m    686\u001b[39m             \u001b[38;5;28msuper\u001b[39m().update(iterable)\n\u001b[32m    687\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[32m    690\u001b[39m     \u001b[38;5;28mself\u001b[39m.update(kwds)\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r'D:\\PIMA\\data_2\\cleaned_3.csv')  # Adjust path as needed\n",
    "\n",
    "# Set up features and target\n",
    "X = data.drop('Diabetes_012', axis=1)  # Adjust column name as needed\n",
    "y = data['Diabetes_012'].astype(int)  # Ensure this has 0, 1, 2 values\n",
    "\n",
    "# Reset indices to ensure they are continuous integers starting from 0\n",
    "X = X.reset_index(drop=True)\n",
    "y = pd.Series(y.values).reset_index(drop=True)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Reset indices again after splitting to avoid any indexing issues\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = pd.Series(y_train.values).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test.values).reset_index(drop=True)\n",
    "\n",
    "# Print class distribution\n",
    "train_counts = np.bincount(y_train.astype(int))\n",
    "print(f\"Training set class distribution:\")\n",
    "for cls, count in enumerate(train_counts):\n",
    "    print(f\"Class {cls}: {count} samples ({count/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "# Function to create balanced subsamples\n",
    "def create_balanced_subset(X, y, n_estimators=10, sampling_ratio=1.5):\n",
    "    \"\"\"\n",
    "    Create multiple balanced datasets by randomly subsampling class 0\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Features\n",
    "    y : Series or array\n",
    "        Target with class 0, 1, 2\n",
    "    n_estimators : int\n",
    "        Number of subsampled datasets to create\n",
    "    sampling_ratio : float\n",
    "        Ratio of class 0 samples to class 1+2 samples\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of tuples (X_subset, y_subset) for each balanced dataset\n",
    "    \"\"\"\n",
    "    # Get indices for each class\n",
    "    idx_class0 = np.where(y == 0)[0]\n",
    "    idx_class1 = np.where(y == 1)[0]\n",
    "    idx_class2 = np.where(y == 2)[0]\n",
    "    \n",
    "    # Count samples in each class\n",
    "    n_class0 = len(idx_class0)\n",
    "    n_class1 = len(idx_class1)\n",
    "    n_class2 = len(idx_class2)\n",
    "    n_minority = n_class1 + n_class2\n",
    "    \n",
    "    # Calculate how many class 0 samples to include in each subset\n",
    "    n_samples_class0 = int(n_minority * sampling_ratio)\n",
    "    \n",
    "    # Make sure we don't try to sample more than available\n",
    "    n_samples_class0 = min(n_samples_class0, n_class0)\n",
    "    \n",
    "    # Create multiple balanced subsets\n",
    "    subsets = []\n",
    "    for i in range(n_estimators):\n",
    "        # Randomly sample class 0 indices without replacement\n",
    "        sampled_idx_class0 = np.random.choice(idx_class0, size=n_samples_class0, replace=False)\n",
    "        \n",
    "        # Combine with all samples from class 1 and 2\n",
    "        subset_indices = np.concatenate([sampled_idx_class0, idx_class1, idx_class2])\n",
    "        \n",
    "        # Create balanced subset - use iloc to index by position, not by label\n",
    "        X_subset = X.iloc[subset_indices]\n",
    "        y_subset = y.iloc[subset_indices]\n",
    "        \n",
    "        # Check class distribution in subset\n",
    "        subset_counts = np.bincount(y_subset.astype(int))\n",
    "        print(f\"Subset {i+1} class distribution: {subset_counts}\")\n",
    "        \n",
    "        subsets.append((X_subset, y_subset))\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "# Create balanced subsets for training\n",
    "n_estimators = 5  # Number of models in the ensemble\n",
    "subsets = create_balanced_subset(X_train, y_train, n_estimators=n_estimators, sampling_ratio=2.0)\n",
    "\n",
    "# Train a model on each balanced subset\n",
    "models = []\n",
    "for i, (X_subset, y_subset) in enumerate(subsets):\n",
    "    print(f\"\\nTraining model {i+1}/{n_estimators}...\")\n",
    "    \n",
    "    # Initialize CatBoost classifier\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=500,  # Reduced iterations for faster training\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='MultiClass',  # Multiclass classification\n",
    "        random_seed=42 + i,  # Different seed for each model\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_subset, y_subset)\n",
    "    \n",
    "    # Add to ensemble\n",
    "    models.append(model)\n",
    "    \n",
    "    # Evaluate individual model\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nModel {i+1} performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function for ensemble prediction - hard voting\n",
    "def ensemble_predict_hard_voting(models, X):\n",
    "    \"\"\"Predict using majority voting from all models\"\"\"\n",
    "    # Get predictions from each model\n",
    "    predictions = np.array([model.predict(X) for model in models])\n",
    "    \n",
    "    # Transpose to get predictions by sample\n",
    "    predictions = predictions.T\n",
    "    \n",
    "    # For each sample, count votes for each class\n",
    "    ensemble_predictions = np.zeros(len(X))\n",
    "    \n",
    "    for i, preds in enumerate(predictions):\n",
    "        # Count occurrences of each class\n",
    "        votes = Counter(preds)\n",
    "        \n",
    "        # Find class with most votes (majority)\n",
    "        ensemble_predictions[i] = votes.most_common(1)[0][0]\n",
    "    \n",
    "    return ensemble_predictions\n",
    "\n",
    "# Function for ensemble prediction - soft voting (averaging probabilities)\n",
    "def ensemble_predict_soft_voting(models, X, weights=None):\n",
    "    \"\"\"Predict using weighted average of probabilities from all models\"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(models)) / len(models)\n",
    "    \n",
    "    # Get probability predictions from each model\n",
    "    probas = np.array([model.predict_proba(X) for model in models])\n",
    "    \n",
    "    # Weight each model's predictions\n",
    "    weighted_probas = np.array([w * p for w, p in zip(weights, probas)])\n",
    "    \n",
    "    # Sum weighted probabilities\n",
    "    avg_probas = np.sum(weighted_probas, axis=0)\n",
    "    \n",
    "    # Return class with highest probability\n",
    "    return np.argmax(avg_probas, axis=1)\n",
    "\n",
    "# Function for weighted ensemble prediction with class-specific focus\n",
    "def ensemble_predict_class_weighted(models, X, class1_weight=2.0, class2_weight=1.5):\n",
    "    \"\"\"\n",
    "    Predict using weighted probabilities that prioritize class 1 and 2 detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : list\n",
    "        List of trained models\n",
    "    X : DataFrame\n",
    "        Features to predict on\n",
    "    class1_weight : float\n",
    "        Weight multiplier for class 1 probabilities\n",
    "    class2_weight : float\n",
    "        Weight multiplier for class 2 probabilities\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0, 1, or 2\n",
    "    \"\"\"\n",
    "    # Get probability predictions from each model\n",
    "    all_probas = np.array([model.predict_proba(X) for model in models])\n",
    "    \n",
    "    # Average probabilities across models\n",
    "    avg_probas = np.mean(all_probas, axis=0)\n",
    "    \n",
    "    # Apply class-specific weights to prioritize class 1 and 2\n",
    "    weighted_probas = avg_probas.copy()\n",
    "    weighted_probas[:, 1] *= class1_weight  # Boost class 1 probabilities\n",
    "    weighted_probas[:, 2] *= class2_weight  # Boost class 2 probabilities\n",
    "    \n",
    "    # Return class with highest weighted probability\n",
    "    return np.argmax(weighted_probas, axis=1)\n",
    "\n",
    "# Evaluate ensemble with hard voting (majority vote)\n",
    "y_pred_hard = ensemble_predict_hard_voting(models, X_test)\n",
    "print(\"\\n----- Ensemble with Hard Voting -----\")\n",
    "print(classification_report(y_test, y_pred_hard))\n",
    "\n",
    "# Evaluate ensemble with soft voting (probability averaging)\n",
    "y_pred_soft = ensemble_predict_soft_voting(models, X_test)\n",
    "print(\"\\n----- Ensemble with Soft Voting -----\")\n",
    "print(classification_report(y_test, y_pred_soft))\n",
    "\n",
    "# Evaluate ensemble with class-weighted voting\n",
    "# Try different weights to prioritize class 1 and 2\n",
    "weight_combinations = [\n",
    "    (1.5, 1.2),  # Moderate boost for classes 1 and 2\n",
    "    (2.0, 1.5),  # Higher boost for class 1 than class 2\n",
    "    (3.0, 2.0),  # Stronger boost for both\n",
    "    (4.0, 2.0),  # Very strong boost for class 1\n",
    "    (2.0, 4.0)   # Very strong boost for class 2\n",
    "]\n",
    "\n",
    "print(\"\\n----- Testing Different Class Weight Combinations -----\")\n",
    "best_avg_recall = 0\n",
    "best_weights = None\n",
    "best_predictions = None\n",
    "\n",
    "for class1_w, class2_w in weight_combinations:\n",
    "    y_pred_weighted = ensemble_predict_class_weighted(models, X_test, class1_weight=class1_w, class2_weight=class2_w)\n",
    "    \n",
    "    # Calculate class-specific recalls\n",
    "    recall_0 = recall_score(y_test == 0, y_pred_weighted == 0)\n",
    "    recall_1 = recall_score(y_test == 1, y_pred_weighted == 1)\n",
    "    recall_2 = recall_score(y_test == 2, y_pred_weighted == 2)\n",
    "    \n",
    "    # Calculate average recall for classes 1 and 2\n",
    "    avg_recall_1_2 = (recall_1 + recall_2) / 2\n",
    "    \n",
    "    print(f\"\\nClass weights: Class 1 = {class1_w}, Class 2 = {class2_w}\")\n",
    "    print(f\"Class 0 recall: {recall_0:.4f}\")\n",
    "    print(f\"Class 1 recall: {recall_1:.4f}\")\n",
    "    print(f\"Class 2 recall: {recall_2:.4f}\")\n",
    "    print(f\"Average recall (classes 1 & 2): {avg_recall_1_2:.4f}\")\n",
    "    \n",
    "    # Check if this is the best combination so far\n",
    "    if avg_recall_1_2 > best_avg_recall:\n",
    "        best_avg_recall = avg_recall_1_2\n",
    "        best_weights = (class1_w, class2_w)\n",
    "        best_predictions = y_pred_weighted\n",
    "\n",
    "# Use best weights for final evaluation\n",
    "print(f\"\\n----- Best Weight Combination: Class 1 = {best_weights[0]}, Class 2 = {best_weights[1]} -----\")\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Class-specific recall analysis for best model\n",
    "print(\"\\nClass-specific Recall for Best Ensemble Model:\")\n",
    "for cls in range(3):\n",
    "    if cls in np.unique(y_test):\n",
    "        recall = recall_score(y_test == cls, best_predictions == cls)\n",
    "        print(f\"Class {cls} Recall: {recall:.4f}\")\n",
    "\n",
    "# Custom performance metric that prioritizes class 1 and 2 recall\n",
    "def calculate_custom_score(y_true, y_pred):\n",
    "    recall_0 = recall_score(y_true == 0, y_pred == 0)\n",
    "    recall_1 = recall_score(y_true == 1, y_pred == 1)\n",
    "    recall_2 = recall_score(y_true == 2, y_pred == 2)\n",
    "    \n",
    "    # Custom score that prioritizes class 2, then class 1, and penalizes high class 0 recall\n",
    "    score = (recall_2 * 0.6) + (recall_1 * 0.4) - (recall_0 * 0.2)\n",
    "    \n",
    "    return score, recall_0, recall_1, recall_2\n",
    "\n",
    "# Calculate custom score for best ensemble\n",
    "custom_score, r0, r1, r2 = calculate_custom_score(y_test, best_predictions)\n",
    "print(f\"\\nCustom Score (prioritizing classes 1 & 2): {custom_score:.4f}\")\n",
    "print(f\"Class 0 recall: {r0:.4f}\")\n",
    "print(f\"Class 1 recall: {r1:.4f}\")\n",
    "print(f\"Class 2 recall: {r2:.4f}\")\n",
    "\n",
    "# Save the ensemble models\n",
    "for i, model in enumerate(models):\n",
    "    model.save_model(f'catboost_ensemble_model_{i+1}.cbm')\n",
    "\n",
    "# Function to make predictions using the ensemble\n",
    "def predict_with_ensemble(X_new, model_paths=None, class1_weight=best_weights[0], class2_weight=best_weights[1]):\n",
    "    \"\"\"\n",
    "    Predict using the ensemble of models with class-weighted voting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : DataFrame\n",
    "        New features to predict on\n",
    "    model_paths : list\n",
    "        List of paths to saved models (if None, uses default paths)\n",
    "    class1_weight : float\n",
    "        Weight for class 1\n",
    "    class2_weight : float\n",
    "        Weight for class 2\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Predictions: 0, 1, or 2\n",
    "    \"\"\"\n",
    "    if model_paths is None:\n",
    "        model_paths = [f'catboost_ensemble_model_{i+1}.cbm' for i in range(n_estimators)]\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = []\n",
    "    for path in model_paths:\n",
    "        model = CatBoostClassifier()\n",
    "        model.load_model(path)\n",
    "        loaded_models.append(model)\n",
    "    \n",
    "    # Make class-weighted predictions\n",
    "    return ensemble_predict_class_weighted(loaded_models, X_new, \n",
    "                                          class1_weight=class1_weight, \n",
    "                                          class2_weight=class2_weight)\n",
    "\n",
    "print(\"\\nExample usage of ensemble prediction function:\")\n",
    "print(\"predictions = predict_with_ensemble(new_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
